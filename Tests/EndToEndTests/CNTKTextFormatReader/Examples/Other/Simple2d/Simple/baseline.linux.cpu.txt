=== Running /home/alrezni/src/cntk_git/build/release/bin/cntk configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config/Simple.cntk currentDirectory=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data RunDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu DataDir=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config OutputDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu DeviceId=-1 timestamping=true Simple_Demo_Train=[SGD=[maxEpochs=3]]
-------------------------------------------------------------------
Build info: 

		Built time: Apr 26 2016 17:04:28
		Last modified date: Tue Apr  5 16:01:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.0
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: alrezni/examples_text
		Build SHA1: 780d0d14f555f568d393793562f374f04af79a73
		Built by alrezni on atleneu04
		Build Path: /home/alrezni/src/cntk_git
-------------------------------------------------------------------
Changed current directory to /home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
04/26/2016 17:09:29: -------------------------------------------------------------------
04/26/2016 17:09:29: Build info: 

04/26/2016 17:09:29: 		Built time: Apr 26 2016 17:04:28
04/26/2016 17:09:29: 		Last modified date: Tue Apr  5 16:01:37 2016
04/26/2016 17:09:29: 		Build type: release
04/26/2016 17:09:29: 		Build target: GPU
04/26/2016 17:09:29: 		With 1bit-SGD: yes
04/26/2016 17:09:29: 		Math lib: acml
04/26/2016 17:09:29: 		CUDA_PATH: /usr/local/cuda-7.0
04/26/2016 17:09:29: 		CUB_PATH: /usr/local/cub-1.4.1
04/26/2016 17:09:29: 		CUDNN_PATH: /usr/local/cudnn-4.0
04/26/2016 17:09:29: 		Build Branch: alrezni/examples_text
04/26/2016 17:09:29: 		Build SHA1: 780d0d14f555f568d393793562f374f04af79a73
04/26/2016 17:09:29: 		Built by alrezni on atleneu04
04/26/2016 17:09:29: 		Build Path: /home/alrezni/src/cntk_git
04/26/2016 17:09:29: -------------------------------------------------------------------

04/26/2016 17:09:29: Running on localhost at 2016/04/26 17:09:29
04/26/2016 17:09:29: Command line: 
/home/alrezni/src/cntk_git/build/release/bin/cntk  configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config/Simple.cntk  currentDirectory=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data  RunDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu  DataDir=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data  ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config  OutputDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu  DeviceId=-1  timestamping=true  Simple_Demo_Train=[SGD=[maxEpochs=3]]



04/26/2016 17:09:29: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/26/2016 17:09:29: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
deviceId = -1
command = Simple_Demo_Train:Simple_Demo_Test:Simple_Demo_Output
precision = "float"
traceLevel = 1
modelPath = "$ModelDir$/simple.dnn"
outputNodeNames = ScaledLogLikelihood
Simple_Demo_Train = [
    action = "train"
    SimpleNetworkBuilder = [
        layerSizes = 2:50*2:2
        trainingCriterion = "CrossEntropyWithSoftmax"
        evalCriterion = "ErrorPrediction"
        layerTypes = "Sigmoid"
        initValueScale = 1.0
        applyMeanVarNorm = true
        uniformInit = true
        needPrior = true
    ]
    SGD = [
        epochSize = 0 
        minibatchSize = 25  
        learningRatesPerMB = 0.5:0.2*20:0.1
        momentumPerMB = 0.9
        dropoutRate = 0.0
        maxEpochs = 10
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/SimpleDataTrain_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Test = [
    action = "test"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action = "write"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
outputNodeNames = PosteriorProb : labels    
outputPath = "$OutputDir$/SimpleOutput"     
    format = [
type = "category"                                
labelMappingFile = "$DataDir$/SimpleMapping.txt" 
sequenceEpilogue = "\t// %s\n"                   
    ]
]
currentDirectory=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
RunDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
DataDir=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config
OutputDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
DeviceId=-1
timestamping=true
Simple_Demo_Train=[SGD=[maxEpochs=3]]

04/26/2016 17:09:29: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/26/2016 17:09:29: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/26/2016 17:09:29: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models"
deviceId = -1
command = Simple_Demo_Train:Simple_Demo_Test:Simple_Demo_Output
precision = "float"
traceLevel = 1
modelPath = "/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn"
outputNodeNames = ScaledLogLikelihood
Simple_Demo_Train = [
    action = "train"
    SimpleNetworkBuilder = [
        layerSizes = 2:50*2:2
        trainingCriterion = "CrossEntropyWithSoftmax"
        evalCriterion = "ErrorPrediction"
        layerTypes = "Sigmoid"
        initValueScale = 1.0
        applyMeanVarNorm = true
        uniformInit = true
        needPrior = true
    ]
    SGD = [
        epochSize = 0 
        minibatchSize = 25  
        learningRatesPerMB = 0.5:0.2*20:0.1
        momentumPerMB = 0.9
        dropoutRate = 0.0
        maxEpochs = 10
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTrain_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Test = [
    action = "test"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action = "write"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
outputNodeNames = PosteriorProb : labels    
outputPath = "/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/SimpleOutput"     
    format = [
type = "category"                                
labelMappingFile = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleMapping.txt" 
sequenceEpilogue = "\t// %s\n"                   
    ]
]
currentDirectory=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
RunDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
DataDir=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config
OutputDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
DeviceId=-1
timestamping=true
Simple_Demo_Train=[SGD=[maxEpochs=3]]

04/26/2016 17:09:29: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/26/2016 17:09:29: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: Simple.cntk:command=Simple_Demo_Train:Simple_Demo_Test:Simple_Demo_Output
configparameters: Simple.cntk:ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Examples/Other/Simple2d/Simple/../Config
configparameters: Simple.cntk:currentDirectory=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
configparameters: Simple.cntk:DataDir=/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data
configparameters: Simple.cntk:deviceId=-1
configparameters: Simple.cntk:ModelDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models
configparameters: Simple.cntk:modelPath=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn
configparameters: Simple.cntk:OutputDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
configparameters: Simple.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: Simple.cntk:precision=float
configparameters: Simple.cntk:RootDir=..
configparameters: Simple.cntk:RunDir=/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu
configparameters: Simple.cntk:Simple_Demo_Output=[
    action = "write"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
outputNodeNames = PosteriorProb : labels    
outputPath = "/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/SimpleOutput"     
    format = [
type = "category"                                
labelMappingFile = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleMapping.txt" 
sequenceEpilogue = "\t// %s\n"                   
    ]
]

configparameters: Simple.cntk:Simple_Demo_Test=[
    action = "test"
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTest_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
]

configparameters: Simple.cntk:Simple_Demo_Train=[
    action = "train"
    SimpleNetworkBuilder = [
        layerSizes = 2:50*2:2
        trainingCriterion = "CrossEntropyWithSoftmax"
        evalCriterion = "ErrorPrediction"
        layerTypes = "Sigmoid"
        initValueScale = 1.0
        applyMeanVarNorm = true
        uniformInit = true
        needPrior = true
    ]
    SGD = [
        epochSize = 0 
        minibatchSize = 25  
        learningRatesPerMB = 0.5:0.2*20:0.1
        momentumPerMB = 0.9
        dropoutRate = 0.0
        maxEpochs = 10
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/alrezni/src/cntk_git/Examples/Other/Simple2d/Data/SimpleDataTrain_cntk_text.txt"
        input = [
            features = [
dim = 2        
                format = "dense"
            ]
            labels = [
dim = 2        
                format = "dense"
            ]
        ]
    ]
] [SGD=[maxEpochs=3]]

configparameters: Simple.cntk:timestamping=true
configparameters: Simple.cntk:traceLevel=1
04/26/2016 17:09:29: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/26/2016 17:09:29: Commands: Simple_Demo_Train Simple_Demo_Test Simple_Demo_Output
04/26/2016 17:09:29: Precision = "float"
04/26/2016 17:09:29: CNTKModelPath: /tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn
04/26/2016 17:09:29: CNTKCommandTrainInfo: Simple_Demo_Train : 3
04/26/2016 17:09:29: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3

04/26/2016 17:09:29: ##############################################################################
04/26/2016 17:09:29: #                                                                            #
04/26/2016 17:09:29: # Action "train"                                                             #
04/26/2016 17:09:29: #                                                                            #
04/26/2016 17:09:29: ##############################################################################

04/26/2016 17:09:29: CNTKCommandTrainBegin: Simple_Demo_Train
SimpleNetworkBuilder Using CPU

04/26/2016 17:09:29: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/26/2016 17:09:29: Created model with 25 nodes on CPU.

04/26/2016 17:09:29: Training criterion node(s):
04/26/2016 17:09:29: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

04/26/2016 17:09:29: Evaluation criterion node(s):

04/26/2016 17:09:29: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0x2373098: {[features Value[2 x *]] }
0x2374a28: {[InvStdOfFeatures Value[2]] }
0x2378908: {[MeanOfFeatures Value[2]] }
0x237c118: {[W0 Value[50 x 2]] }
0x237c708: {[B0 Value[50 x 1]] }
0x237d6f8: {[W1 Value[50 x 50]] }
0x2380278: {[B1 Value[50 x 1]] }
0x2381158: {[W2 Value[2 x 50]] }
0x2381718: {[B2 Value[2 x 1]] }
0x23821e8: {[labels Value[2 x *]] }
0x2382f68: {[Prior Value[2]] }
0x2388c58: {[LogOfPrior Value[2]] }
0x2389848: {[EvalErrorPrediction Value[1]] }
0x238af88: {[MVNormalizedFeatures Value[2 x *]] }
0x238b2a8: {[W0*features Value[50 x *]] }
0x238b408: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0x238b568: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0x238b728: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0x238b8e8: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0x238baa8: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0x238bc68: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0x238be28: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0x238bfe8: {[CrossEntropyWithSoftmax Value[1]] }
0x238cd68: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0x238cf28: {[CrossEntropyWithSoftmax Gradient[1]] }
0x238d0e8: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0x238d2a8: {[W2*H1 Gradient[2 x 1 x *]] }
0x238d468: {[B2 Gradient[2 x 1]] }


04/26/2016 17:09:29: Precomputing --> 3 PreCompute nodes found.

04/26/2016 17:09:29: 	MeanOfFeatures = Mean()
04/26/2016 17:09:29: 	InvStdOfFeatures = InvStdDev()
04/26/2016 17:09:29: 	Prior = Mean()

04/26/2016 17:09:29: Precomputing --> Completed.


04/26/2016 17:09:29: Starting Epoch 1: learning rate per sample = 0.020000  effective momentum = 0.900000  momentum as time constant = 237.3 samples

04/26/2016 17:09:29: Starting minibatch loop.
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[   1-  10]: SamplesSeen = 250; TrainLossPerSample =  0.69966235; EvalErr[0]PerSample = 0.51200000; TotalTime = 0.0159s; SamplesPerSecond = 15760.9
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  11-  20]: SamplesSeen = 250; TrainLossPerSample =  0.70639648; EvalErr[0]PerSample = 0.49600000; TotalTime = 0.0127s; SamplesPerSecond = 19748.8
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  21-  30]: SamplesSeen = 250; TrainLossPerSample =  0.70470264; EvalErr[0]PerSample = 0.52400000; TotalTime = 0.0066s; SamplesPerSecond = 37673.3
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  31-  40]: SamplesSeen = 250; TrainLossPerSample =  0.69813501; EvalErr[0]PerSample = 0.52400000; TotalTime = 0.0133s; SamplesPerSecond = 18858.0
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  41-  50]: SamplesSeen = 250; TrainLossPerSample =  0.73551416; EvalErr[0]PerSample = 0.57600000; TotalTime = 0.0133s; SamplesPerSecond = 18840.9
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  51-  60]: SamplesSeen = 250; TrainLossPerSample =  0.72432324; EvalErr[0]PerSample = 0.50800000; TotalTime = 0.0093s; SamplesPerSecond = 26824.0
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  61-  70]: SamplesSeen = 250; TrainLossPerSample =  0.73327588; EvalErr[0]PerSample = 0.48800000; TotalTime = 0.0099s; SamplesPerSecond = 25211.8
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  71-  80]: SamplesSeen = 250; TrainLossPerSample =  0.70092627; EvalErr[0]PerSample = 0.50400000; TotalTime = 0.0133s; SamplesPerSecond = 18801.2
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  81-  90]: SamplesSeen = 250; TrainLossPerSample =  0.72354980; EvalErr[0]PerSample = 0.46000000; TotalTime = 0.0127s; SamplesPerSecond = 19728.5
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[  91- 100]: SamplesSeen = 250; TrainLossPerSample =  0.72148096; EvalErr[0]PerSample = 0.52000000; TotalTime = 0.0067s; SamplesPerSecond = 37498.1
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 101- 110]: SamplesSeen = 250; TrainLossPerSample =  0.69814941; EvalErr[0]PerSample = 0.48000000; TotalTime = 0.0132s; SamplesPerSecond = 18915.0
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 111- 120]: SamplesSeen = 250; TrainLossPerSample =  0.70699121; EvalErr[0]PerSample = 0.54800000; TotalTime = 0.0127s; SamplesPerSecond = 19745.7
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 121- 130]: SamplesSeen = 250; TrainLossPerSample =  0.69898437; EvalErr[0]PerSample = 0.50000000; TotalTime = 0.0067s; SamplesPerSecond = 37219.0
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 131- 140]: SamplesSeen = 250; TrainLossPerSample =  0.71712695; EvalErr[0]PerSample = 0.54000000; TotalTime = 0.0125s; SamplesPerSecond = 20014.4
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 141- 150]: SamplesSeen = 250; TrainLossPerSample =  0.69470703; EvalErr[0]PerSample = 0.52400000; TotalTime = 0.0127s; SamplesPerSecond = 19723.9
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 151- 160]: SamplesSeen = 250; TrainLossPerSample =  0.71375879; EvalErr[0]PerSample = 0.51200000; TotalTime = 0.0067s; SamplesPerSecond = 37257.8
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 161- 170]: SamplesSeen = 250; TrainLossPerSample =  0.70381641; EvalErr[0]PerSample = 0.47600000; TotalTime = 0.0166s; SamplesPerSecond = 15095.7
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 171- 180]: SamplesSeen = 250; TrainLossPerSample =  0.71748633; EvalErr[0]PerSample = 0.48800000; TotalTime = 0.0099s; SamplesPerSecond = 25161.0
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 181- 190]: SamplesSeen = 250; TrainLossPerSample =  0.71863281; EvalErr[0]PerSample = 0.50400000; TotalTime = 0.0126s; SamplesPerSecond = 19798.8
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 191- 200]: SamplesSeen = 250; TrainLossPerSample =  0.70715234; EvalErr[0]PerSample = 0.50000000; TotalTime = 0.0133s; SamplesPerSecond = 18768.8
04/26/2016 17:09:29:  Epoch[ 1 of 3]-Minibatch[ 201- 210]: SamplesSeen = 250; TrainLossPerSample =  0.70401074; EvalErr[0]PerSample = 0.48000000; TotalTime = 0.0067s; SamplesPerSecond = 37408.3
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 211- 220]: SamplesSeen = 250; TrainLossPerSample =  0.70599414; EvalErr[0]PerSample = 0.48400000; TotalTime = 0.0125s; SamplesPerSecond = 19950.5
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 221- 230]: SamplesSeen = 250; TrainLossPerSample =  0.69628711; EvalErr[0]PerSample = 0.48000000; TotalTime = 0.0127s; SamplesPerSecond = 19723.9
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 231- 240]: SamplesSeen = 250; TrainLossPerSample =  0.75920898; EvalErr[0]PerSample = 0.51200000; TotalTime = 0.0067s; SamplesPerSecond = 37413.9
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 241- 250]: SamplesSeen = 250; TrainLossPerSample =  0.70542578; EvalErr[0]PerSample = 0.43600000; TotalTime = 0.0132s; SamplesPerSecond = 18919.3
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 251- 260]: SamplesSeen = 250; TrainLossPerSample =  0.70643945; EvalErr[0]PerSample = 0.46400000; TotalTime = 0.0126s; SamplesPerSecond = 19775.4
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 261- 270]: SamplesSeen = 250; TrainLossPerSample =  0.72481641; EvalErr[0]PerSample = 0.51600000; TotalTime = 0.0067s; SamplesPerSecond = 37458.8
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 271- 280]: SamplesSeen = 250; TrainLossPerSample =  0.71133594; EvalErr[0]PerSample = 0.55600000; TotalTime = 0.0098s; SamplesPerSecond = 25411.7
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 281- 290]: SamplesSeen = 250; TrainLossPerSample =  0.68605664; EvalErr[0]PerSample = 0.47200000; TotalTime = 0.0127s; SamplesPerSecond = 19695.9
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 291- 300]: SamplesSeen = 250; TrainLossPerSample =  0.69535352; EvalErr[0]PerSample = 0.47200000; TotalTime = 0.0100s; SamplesPerSecond = 25090.3
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 301- 310]: SamplesSeen = 250; TrainLossPerSample =  0.68741797; EvalErr[0]PerSample = 0.45200000; TotalTime = 0.0099s; SamplesPerSecond = 25237.2
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 311- 320]: SamplesSeen = 250; TrainLossPerSample =  0.67916406; EvalErr[0]PerSample = 0.46000000; TotalTime = 0.0133s; SamplesPerSecond = 18819.6
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 321- 330]: SamplesSeen = 250; TrainLossPerSample =  0.67841992; EvalErr[0]PerSample = 0.44800000; TotalTime = 0.0127s; SamplesPerSecond = 19708.3
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 331- 340]: SamplesSeen = 250; TrainLossPerSample =  0.68038477; EvalErr[0]PerSample = 0.49200000; TotalTime = 0.0067s; SamplesPerSecond = 37492.5
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 341- 350]: SamplesSeen = 250; TrainLossPerSample =  0.61937109; EvalErr[0]PerSample = 0.30400000; TotalTime = 0.0125s; SamplesPerSecond = 19920.3
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 351- 360]: SamplesSeen = 250; TrainLossPerSample =  0.57844141; EvalErr[0]PerSample = 0.27200000; TotalTime = 0.0127s; SamplesPerSecond = 19697.4
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 361- 370]: SamplesSeen = 250; TrainLossPerSample =  0.49124023; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0067s; SamplesPerSecond = 37509.4
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 371- 380]: SamplesSeen = 250; TrainLossPerSample =  0.39071289; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0132s; SamplesPerSecond = 18905.0
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 381- 390]: SamplesSeen = 250; TrainLossPerSample =  0.27650586; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0092s; SamplesPerSecond = 27047.5
04/26/2016 17:09:30:  Epoch[ 1 of 3]-Minibatch[ 391- 400]: SamplesSeen = 250; TrainLossPerSample =  0.26430078; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0127s; SamplesPerSecond = 19700.6
04/26/2016 17:09:30: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 0.6666415; TotalSamplesSeen = 10000; EvalErrPerSample = 0.4443; AvgLearningRatePerSample = 0.02; EpochTime=0.449824
04/26/2016 17:09:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn.1'

04/26/2016 17:09:30: Starting Epoch 2: learning rate per sample = 0.008000  effective momentum = 0.900000  momentum as time constant = 237.3 samples

04/26/2016 17:09:30: Starting minibatch loop.
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[   1-  10, 2.50%]: SamplesSeen = 250; TrainLossPerSample =  0.20732678; EvalErr[0]PerSample = 0.09200000; TotalTime = 0.0084s; SamplesPerSecond = 29840.1
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  11-  20, 5.00%]: SamplesSeen = 250; TrainLossPerSample =  0.19684015; EvalErr[0]PerSample = 0.10000000; TotalTime = 0.0096s; SamplesPerSecond = 26087.9
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  21-  30, 7.50%]: SamplesSeen = 250; TrainLossPerSample =  0.16083588; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0089s; SamplesPerSecond = 28175.4
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  31-  40, 10.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13558752; EvalErr[0]PerSample = 0.04400000; TotalTime = 0.0143s; SamplesPerSecond = 17425.2
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  41-  50, 12.50%]: SamplesSeen = 250; TrainLossPerSample =  0.17992950; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0216s; SamplesPerSecond = 11576.8
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  51-  60, 15.00%]: SamplesSeen = 250; TrainLossPerSample =  0.17858063; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0170s; SamplesPerSecond = 14729.3
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  61-  70, 17.50%]: SamplesSeen = 250; TrainLossPerSample =  0.16847546; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0096s; SamplesPerSecond = 26128.8
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  71-  80, 20.00%]: SamplesSeen = 250; TrainLossPerSample =  0.16359399; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0061s; SamplesPerSecond = 41098.1
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  81-  90, 22.50%]: SamplesSeen = 250; TrainLossPerSample =  0.19534705; EvalErr[0]PerSample = 0.10800000; TotalTime = 0.0095s; SamplesPerSecond = 26455.0
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[  91- 100, 25.00%]: SamplesSeen = 250; TrainLossPerSample =  0.19363660; EvalErr[0]PerSample = 0.10000000; TotalTime = 0.0127s; SamplesPerSecond = 19644.8
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 27.50%]: SamplesSeen = 250; TrainLossPerSample =  0.12703638; EvalErr[0]PerSample = 0.04800000; TotalTime = 0.0089s; SamplesPerSecond = 28242.2
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 30.00%]: SamplesSeen = 250; TrainLossPerSample =  0.18622827; EvalErr[0]PerSample = 0.10000000; TotalTime = 0.0094s; SamplesPerSecond = 26666.7
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 32.50%]: SamplesSeen = 250; TrainLossPerSample =  0.11595044; EvalErr[0]PerSample = 0.04400000; TotalTime = 0.0131s; SamplesPerSecond = 19146.8
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 131- 140, 35.00%]: SamplesSeen = 250; TrainLossPerSample =  0.16689380; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0061s; SamplesPerSecond = 41030.7
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 141- 150, 37.50%]: SamplesSeen = 250; TrainLossPerSample =  0.15822559; EvalErr[0]PerSample = 0.08400000; TotalTime = 0.0122s; SamplesPerSecond = 20421.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 151- 160, 40.00%]: SamplesSeen = 250; TrainLossPerSample =  0.18381909; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0130s; SamplesPerSecond = 19303.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 161- 170, 42.50%]: SamplesSeen = 250; TrainLossPerSample =  0.18274048; EvalErr[0]PerSample = 0.08800000; TotalTime = 0.0060s; SamplesPerSecond = 41336.0
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 171- 180, 45.00%]: SamplesSeen = 250; TrainLossPerSample =  0.18638428; EvalErr[0]PerSample = 0.09200000; TotalTime = 0.0160s; SamplesPerSecond = 15649.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 181- 190, 47.50%]: SamplesSeen = 250; TrainLossPerSample =  0.20111572; EvalErr[0]PerSample = 0.10400000; TotalTime = 0.0095s; SamplesPerSecond = 26407.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 191- 200, 50.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13185034; EvalErr[0]PerSample = 0.06000000; TotalTime = 0.0130s; SamplesPerSecond = 19290.1
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 201- 210, 52.50%]: SamplesSeen = 250; TrainLossPerSample =  0.13692554; EvalErr[0]PerSample = 0.06000000; TotalTime = 0.0061s; SamplesPerSecond = 41003.8
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 211- 220, 55.00%]: SamplesSeen = 250; TrainLossPerSample =  0.15396802; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0122s; SamplesPerSecond = 20448.2
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 221- 230, 57.50%]: SamplesSeen = 250; TrainLossPerSample =  0.15347241; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0130s; SamplesPerSecond = 19287.1
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 231- 240, 60.00%]: SamplesSeen = 250; TrainLossPerSample =  0.14583887; EvalErr[0]PerSample = 0.06800000; TotalTime = 0.0060s; SamplesPerSecond = 41356.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 241- 250, 62.50%]: SamplesSeen = 250; TrainLossPerSample =  0.12333276; EvalErr[0]PerSample = 0.04800000; TotalTime = 0.0121s; SamplesPerSecond = 20681.7
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 251- 260, 65.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13958154; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0061s; SamplesPerSecond = 41132.0
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 261- 270, 67.50%]: SamplesSeen = 250; TrainLossPerSample =  0.12539844; EvalErr[0]PerSample = 0.04400000; TotalTime = 0.0129s; SamplesPerSecond = 19396.4
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 271- 280, 70.00%]: SamplesSeen = 250; TrainLossPerSample =  0.19014404; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0129s; SamplesPerSecond = 19334.9
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 281- 290, 72.50%]: SamplesSeen = 250; TrainLossPerSample =  0.17959521; EvalErr[0]PerSample = 0.08800000; TotalTime = 0.0061s; SamplesPerSecond = 41071.1
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 291- 300, 75.00%]: SamplesSeen = 250; TrainLossPerSample =  0.18899121; EvalErr[0]PerSample = 0.09600000; TotalTime = 0.0128s; SamplesPerSecond = 19514.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 301- 310, 77.50%]: SamplesSeen = 250; TrainLossPerSample =  0.17525586; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0130s; SamplesPerSecond = 19235.2
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 311- 320, 80.00%]: SamplesSeen = 250; TrainLossPerSample =  0.14735645; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0061s; SamplesPerSecond = 41091.4
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 321- 330, 82.50%]: SamplesSeen = 250; TrainLossPerSample =  0.13705518; EvalErr[0]PerSample = 0.06000000; TotalTime = 0.0122s; SamplesPerSecond = 20451.6
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 331- 340, 85.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13610693; EvalErr[0]PerSample = 0.05200000; TotalTime = 0.0061s; SamplesPerSecond = 41192.9
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 341- 350, 87.50%]: SamplesSeen = 250; TrainLossPerSample =  0.13555811; EvalErr[0]PerSample = 0.05600000; TotalTime = 0.0122s; SamplesPerSecond = 20411.5
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 351- 360, 90.00%]: SamplesSeen = 250; TrainLossPerSample =  0.14883594; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0130s; SamplesPerSecond = 19278.2
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 361- 370, 92.50%]: SamplesSeen = 250; TrainLossPerSample =  0.14724707; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0061s; SamplesPerSecond = 41295.0
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 371- 380, 95.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13130469; EvalErr[0]PerSample = 0.05600000; TotalTime = 0.0129s; SamplesPerSecond = 19432.6
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 381- 390, 97.50%]: SamplesSeen = 250; TrainLossPerSample =  0.19636084; EvalErr[0]PerSample = 0.11600000; TotalTime = 0.0124s; SamplesPerSecond = 20143.4
04/26/2016 17:09:30:  Epoch[ 2 of 3]-Minibatch[ 391- 400, 100.00%]: SamplesSeen = 250; TrainLossPerSample =  0.15681836; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0061s; SamplesPerSecond = 41281.4
04/26/2016 17:09:30: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 0.16173864; TotalSamplesSeen = 20000; EvalErrPerSample = 0.0752; AvgLearningRatePerSample = 0.0080000004; EpochTime=0.428593
04/26/2016 17:09:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn.2'

04/26/2016 17:09:30: Starting Epoch 3: learning rate per sample = 0.008000  effective momentum = 0.900000  momentum as time constant = 237.3 samples

04/26/2016 17:09:30: Starting minibatch loop.
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[   1-  10, 2.50%]: SamplesSeen = 250; TrainLossPerSample =  0.18214960; EvalErr[0]PerSample = 0.08400000; TotalTime = 0.0106s; SamplesPerSecond = 23580.5
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  11-  20, 5.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13526825; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0124s; SamplesPerSecond = 20218.4
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  21-  30, 7.50%]: SamplesSeen = 250; TrainLossPerSample =  0.14344995; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0120s; SamplesPerSecond = 20901.3
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  31-  40, 10.00%]: SamplesSeen = 250; TrainLossPerSample =  0.12557471; EvalErr[0]PerSample = 0.05200000; TotalTime = 0.0061s; SamplesPerSecond = 41044.2
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  41-  50, 12.50%]: SamplesSeen = 250; TrainLossPerSample =  0.17627924; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0122s; SamplesPerSecond = 20468.3
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  51-  60, 15.00%]: SamplesSeen = 250; TrainLossPerSample =  0.17585291; EvalErr[0]PerSample = 0.10400000; TotalTime = 0.0120s; SamplesPerSecond = 20892.5
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  61-  70, 17.50%]: SamplesSeen = 250; TrainLossPerSample =  0.14716791; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0124s; SamplesPerSecond = 20169.4
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  71-  80, 20.00%]: SamplesSeen = 250; TrainLossPerSample =  0.16757751; EvalErr[0]PerSample = 0.08400000; TotalTime = 0.0061s; SamplesPerSecond = 41308.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  81-  90, 22.50%]: SamplesSeen = 250; TrainLossPerSample =  0.10314917; EvalErr[0]PerSample = 0.04000000; TotalTime = 0.0122s; SamplesPerSecond = 20408.2
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[  91- 100, 25.00%]: SamplesSeen = 250; TrainLossPerSample =  0.20322217; EvalErr[0]PerSample = 0.11200000; TotalTime = 0.0095s; SamplesPerSecond = 26313.0
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 27.50%]: SamplesSeen = 250; TrainLossPerSample =  0.16604797; EvalErr[0]PerSample = 0.08800000; TotalTime = 0.0094s; SamplesPerSecond = 26547.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 30.00%]: SamplesSeen = 250; TrainLossPerSample =  0.15105725; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0130s; SamplesPerSecond = 19282.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 32.50%]: SamplesSeen = 250; TrainLossPerSample =  0.19206934; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0061s; SamplesPerSecond = 41315.5
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 131- 140, 35.00%]: SamplesSeen = 250; TrainLossPerSample =  0.13667065; EvalErr[0]PerSample = 0.06800000; TotalTime = 0.0123s; SamplesPerSecond = 20374.9
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 141- 150, 37.50%]: SamplesSeen = 250; TrainLossPerSample =  0.20713037; EvalErr[0]PerSample = 0.08800000; TotalTime = 0.0130s; SamplesPerSecond = 19273.8
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 151- 160, 40.00%]: SamplesSeen = 250; TrainLossPerSample =  0.12862158; EvalErr[0]PerSample = 0.05600000; TotalTime = 0.0061s; SamplesPerSecond = 41220.1
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 161- 170, 42.50%]: SamplesSeen = 250; TrainLossPerSample =  0.17174683; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0122s; SamplesPerSecond = 20419.8
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 171- 180, 45.00%]: SamplesSeen = 250; TrainLossPerSample =  0.16493628; EvalErr[0]PerSample = 0.08400000; TotalTime = 0.0118s; SamplesPerSecond = 21200.8
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 181- 190, 47.50%]: SamplesSeen = 250; TrainLossPerSample =  0.14843726; EvalErr[0]PerSample = 0.05600000; TotalTime = 0.0061s; SamplesPerSecond = 41267.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 191- 200, 50.00%]: SamplesSeen = 250; TrainLossPerSample =  0.12574292; EvalErr[0]PerSample = 0.06800000; TotalTime = 0.0123s; SamplesPerSecond = 20401.5
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 201- 210, 52.50%]: SamplesSeen = 250; TrainLossPerSample =  0.13455151; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0061s; SamplesPerSecond = 41267.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 211- 220, 55.00%]: SamplesSeen = 250; TrainLossPerSample =  0.16762988; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0154s; SamplesPerSecond = 16275.0
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 221- 230, 57.50%]: SamplesSeen = 250; TrainLossPerSample =  0.22347461; EvalErr[0]PerSample = 0.10400000; TotalTime = 0.0095s; SamplesPerSecond = 26404.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 231- 240, 60.00%]: SamplesSeen = 250; TrainLossPerSample =  0.18213623; EvalErr[0]PerSample = 0.10800000; TotalTime = 0.0130s; SamplesPerSecond = 19294.6
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 241- 250, 62.50%]: SamplesSeen = 250; TrainLossPerSample =  0.19970923; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0061s; SamplesPerSecond = 41199.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 251- 260, 65.00%]: SamplesSeen = 250; TrainLossPerSample =  0.22695947; EvalErr[0]PerSample = 0.12800000; TotalTime = 0.0123s; SamplesPerSecond = 20396.5
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 261- 270, 67.50%]: SamplesSeen = 250; TrainLossPerSample =  0.12664502; EvalErr[0]PerSample = 0.06000000; TotalTime = 0.0130s; SamplesPerSecond = 19279.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 271- 280, 70.00%]: SamplesSeen = 250; TrainLossPerSample =  0.15838037; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0061s; SamplesPerSecond = 41267.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 281- 290, 72.50%]: SamplesSeen = 250; TrainLossPerSample =  0.11555566; EvalErr[0]PerSample = 0.05600000; TotalTime = 0.0123s; SamplesPerSecond = 20353.3
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 291- 300, 75.00%]: SamplesSeen = 250; TrainLossPerSample =  0.14157520; EvalErr[0]PerSample = 0.07200000; TotalTime = 0.0130s; SamplesPerSecond = 19279.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 301- 310, 77.50%]: SamplesSeen = 250; TrainLossPerSample =  0.18558350; EvalErr[0]PerSample = 0.09200000; TotalTime = 0.0061s; SamplesPerSecond = 41308.7
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 311- 320, 80.00%]: SamplesSeen = 250; TrainLossPerSample =  0.15083594; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0123s; SamplesPerSecond = 20378.2
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 321- 330, 82.50%]: SamplesSeen = 250; TrainLossPerSample =  0.12831787; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0125s; SamplesPerSecond = 19942.6
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 331- 340, 85.00%]: SamplesSeen = 250; TrainLossPerSample =  0.17656494; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0130s; SamplesPerSecond = 19266.3
04/26/2016 17:09:30:  Epoch[ 3 of 3]-Minibatch[ 341- 350, 87.50%]: SamplesSeen = 250; TrainLossPerSample =  0.14956396; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0061s; SamplesPerSecond = 41260.9
04/26/2016 17:09:31:  Epoch[ 3 of 3]-Minibatch[ 351- 360, 90.00%]: SamplesSeen = 250; TrainLossPerSample =  0.11451660; EvalErr[0]PerSample = 0.04800000; TotalTime = 0.0128s; SamplesPerSecond = 19461.3
04/26/2016 17:09:31:  Epoch[ 3 of 3]-Minibatch[ 361- 370, 92.50%]: SamplesSeen = 250; TrainLossPerSample =  0.16392383; EvalErr[0]PerSample = 0.07600000; TotalTime = 0.0130s; SamplesPerSecond = 19267.8
04/26/2016 17:09:31:  Epoch[ 3 of 3]-Minibatch[ 371- 380, 95.00%]: SamplesSeen = 250; TrainLossPerSample =  0.14811230; EvalErr[0]PerSample = 0.06400000; TotalTime = 0.0061s; SamplesPerSecond = 41254.1
04/26/2016 17:09:31:  Epoch[ 3 of 3]-Minibatch[ 381- 390, 97.50%]: SamplesSeen = 250; TrainLossPerSample =  0.16003760; EvalErr[0]PerSample = 0.08000000; TotalTime = 0.0129s; SamplesPerSecond = 19440.1
04/26/2016 17:09:31:  Epoch[ 3 of 3]-Minibatch[ 391- 400, 100.00%]: SamplesSeen = 250; TrainLossPerSample =  0.17969775; EvalErr[0]PerSample = 0.09600000; TotalTime = 0.0130s; SamplesPerSecond = 19278.2
04/26/2016 17:09:31: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 0.15964808; TotalSamplesSeen = 30000; EvalErrPerSample = 0.0775; AvgLearningRatePerSample = 0.0080000004; EpochTime=0.425186
04/26/2016 17:09:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/Models/simple.dnn'
04/26/2016 17:09:31: CNTKCommandTrainEnd: Simple_Demo_Train

04/26/2016 17:09:31: Action "train" complete.


04/26/2016 17:09:31: ##############################################################################
04/26/2016 17:09:31: #                                                                            #
04/26/2016 17:09:31: # Action "test"                                                              #
04/26/2016 17:09:31: #                                                                            #
04/26/2016 17:09:31: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [EvalErrorPrediction Gradient[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [ScaledLogLikelihood Value[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x2378a68: {[B1 Value[50 x 1]] }
0x2378d68: {[B2 Value[2 x 1]] }
0x237c248: {[MVNormalizedFeatures Value[2 x *1]] }
0x237c5f8: {[W0*features Value[50 x *1]] }
0x237c7b8: {[W0*features+B0 Value[50 x 1 x *1]] }
0x237c978: {[H1 Value[50 x 1 x *1]] }
0x237cb38: {[W1*H1 Value[50 x 1 x *1]] }
0x237ccf8: {[W1*H1+B1 Value[50 x 1 x *1]] }
0x237ceb8: {[H2 Value[50 x 1 x *1]] }
0x237f7d8: {[W2*H1 Value[2 x 1 x *1]] }
0x237f998: {[HLast Value[2 x 1 x *1]] }
0x237fb58: {[CrossEntropyWithSoftmax Value[1]] }
0x23800c8: {[EvalErrorPrediction Value[1]] }
0x2383138: {[B0 Value[50 x 1]] }
0x2384588: {[W2 Value[2 x 50]] }
0x2385888: {[InvStdOfFeatures Value[2]] }
0x23867e8: {[Prior Value[2]] }
0x2389b38: {[features Value[2 x *1]] }
0x238a718: {[labels Value[2 x *1]] }
0x238aed8: {[MeanOfFeatures Value[2]] }
0x238d418: {[LogOfPrior Value[2]] }
0x238d8b8: {[W0 Value[50 x 2]] }
0x238e518: {[W1 Value[50 x 50]] }

Final Results: Minibatch[1-1]: SamplesSeen = 603    EvalErrorPrediction: ErrorPrediction/Sample = 0.059701493    CrossEntropyWithSoftmax: CrossEntropyWithSoftmax/Sample = 0.13085309    Perplexity = 1.1398003    

04/26/2016 17:09:31: Action "test" complete.


04/26/2016 17:09:31: ##############################################################################
04/26/2016 17:09:31: #                                                                            #
04/26/2016 17:09:31: # Action "write"                                                             #
04/26/2016 17:09:31: #                                                                            #
04/26/2016 17:09:31: ##############################################################################


Post-processing network...

8 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()
	labels = InputValue()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [ScaledLogLikelihood Value[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0x237a1a8: {[Prior Value[2]] }
0x237db08: {[LogOfPrior Value[2]] }
0x237f2c8: {[MVNormalizedFeatures Value[2 x *2]] }
0x237f678: {[W0*features Value[50 x *2]] }
0x237f838: {[W0*features+B0 Value[50 x 1 x *2]] }
0x237f9f8: {[H1 Value[50 x 1 x *2]] }
0x237fbb8: {[W1*H1 Value[50 x 1 x *2]] }
0x237fd78: {[W1*H1+B1 Value[50 x 1 x *2]] }
0x237ff38: {[H2 Value[50 x 1 x *2]] }
0x23800f8: {[W2*H1 Value[2 x 1 x *2]] }
0x23802b8: {[HLast Value[2 x 1 x *2]] }
0x23804a8: {[PosteriorProb Value[2 x 1 x *2]] }
0x2382e88: {[B0 Value[50 x 1]] }
0x2383638: {[B1 Value[50 x 1]] }
0x2387258: {[W0 Value[50 x 2]] }
0x2387ef8: {[W1 Value[50 x 50]] }
0x23894e8: {[features Value[2 x *2]] }
0x238a038: {[InvStdOfFeatures Value[2]] }
0x238a6e8: {[B2 Value[2 x 1]] }
0x238b438: {[W2 Value[2 x 50]] }
0x238deb8: {[labels Value[2 x *2]] }
0x238e678: {[MeanOfFeatures Value[2]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160426170928.688721/CNTKTextFormatReader/Examples/Other/Simple2d_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

04/26/2016 17:09:31: Action "write" complete.

04/26/2016 17:09:31: __COMPLETED__