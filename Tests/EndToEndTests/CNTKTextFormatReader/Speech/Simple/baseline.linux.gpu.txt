=== Running /home/alrezni/src/cntk_git/build/release/bin/cntk configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple/Speech_Simple.cntk currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Apr 22 2016 10:15:37
		Last modified date: Tue Apr  5 16:01:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.0
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: alrezni/examples_text
		Build SHA1: 6a74de8e569af56e61a14d762716930c397b5c90
		Built by alrezni on atleneu04
		Build Path: /home/alrezni/src/cntk_git
-------------------------------------------------------------------
Changed current directory to /home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
04/22/2016 11:15:35: -------------------------------------------------------------------
04/22/2016 11:15:35: Build info: 

04/22/2016 11:15:35: 		Built time: Apr 22 2016 10:15:37
04/22/2016 11:15:35: 		Last modified date: Tue Apr  5 16:01:37 2016
04/22/2016 11:15:35: 		Build type: release
04/22/2016 11:15:35: 		Build target: GPU
04/22/2016 11:15:35: 		With 1bit-SGD: no
04/22/2016 11:15:35: 		Math lib: acml
04/22/2016 11:15:35: 		CUDA_PATH: /usr/local/cuda-7.0
04/22/2016 11:15:35: 		CUB_PATH: /usr/local/cub-1.4.1
04/22/2016 11:15:35: 		CUDNN_PATH: /usr/local/cudnn-4.0
04/22/2016 11:15:35: 		Build Branch: alrezni/examples_text
04/22/2016 11:15:35: 		Build SHA1: 6a74de8e569af56e61a14d762716930c397b5c90
04/22/2016 11:15:35: 		Built by alrezni on atleneu04
04/22/2016 11:15:35: 		Build Path: /home/alrezni/src/cntk_git
04/22/2016 11:15:35: -------------------------------------------------------------------

04/22/2016 11:15:35: Running on localhost at 2016/04/22 11:15:35
04/22/2016 11:15:35: Command line: 
/home/alrezni/src/cntk_git/build/release/bin/cntk  configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple/Speech_Simple.cntk  currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu  DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple  OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu  DeviceId=0  timestamping=true



04/22/2016 11:15:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/22/2016 11:15:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=$DataDir$/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=$DataDir$/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DeviceId=0
timestamping=true

04/22/2016 11:15:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/22/2016 11:15:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/22/2016 11:15:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DeviceId=0
timestamping=true

04/22/2016 11:15:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/22/2016 11:15:35: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: Speech_Simple.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: Speech_Simple.cntk:ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
configparameters: Speech_Simple.cntk:currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
configparameters: Speech_Simple.cntk:DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
configparameters: Speech_Simple.cntk:deviceId=0
configparameters: Speech_Simple.cntk:DeviceNumber=-1
configparameters: Speech_Simple.cntk:modelPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
configparameters: Speech_Simple.cntk:OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
configparameters: Speech_Simple.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: Speech_Simple.cntk:precision=float
configparameters: Speech_Simple.cntk:RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
configparameters: Speech_Simple.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]

configparameters: Speech_Simple.cntk:Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: Speech_Simple.cntk:timestamping=true
configparameters: Speech_Simple.cntk:traceLevel=1
04/22/2016 11:15:35: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/22/2016 11:15:35: Commands: Simple_Demo Simple_Demo_Output
04/22/2016 11:15:35: Precision = "float"
04/22/2016 11:15:35: CNTKModelPath: /tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
04/22/2016 11:15:35: CNTKCommandTrainInfo: Simple_Demo : 50
04/22/2016 11:15:35: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

04/22/2016 11:15:35: ##############################################################################
04/22/2016 11:15:35: #                                                                            #
04/22/2016 11:15:35: # Action "train"                                                             #
04/22/2016 11:15:35: #                                                                            #
04/22/2016 11:15:35: ##############################################################################

04/22/2016 11:15:35: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

04/22/2016 11:15:35: Creating virgin network.
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/22/2016 11:15:35: Created model with 25 nodes on GPU 0.

04/22/2016 11:15:35: Training criterion node(s):
04/22/2016 11:15:35: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

04/22/2016 11:15:35: Evaluation criterion node(s):

04/22/2016 11:15:35: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

04/22/2016 11:15:35: Precomputing --> 3 PreCompute nodes found.

04/22/2016 11:15:35: 	MeanOfFeatures = Mean()
04/22/2016 11:15:35: 	InvStdOfFeatures = InvStdDev()
04/22/2016 11:15:35: 	Prior = Mean()

04/22/2016 11:15:36: Precomputing --> Completed.


04/22/2016 11:15:36: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[   1-  10]: SamplesSeen = 1280; TrainLossPerSample =  0.81617508; EvalErr[0]PerSample = 0.51796875; TotalTime = 0.0069s; SamplesPerSecond = 185992.4
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  11-  20]: SamplesSeen = 1280; TrainLossPerSample =  0.73377447; EvalErr[0]PerSample = 0.51796875; TotalTime = 0.0058s; SamplesPerSecond = 221760.2
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  21-  30]: SamplesSeen = 1280; TrainLossPerSample =  0.71287031; EvalErr[0]PerSample = 0.48906250; TotalTime = 0.0056s; SamplesPerSecond = 227111.4
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  31-  40]: SamplesSeen = 1280; TrainLossPerSample =  0.69614067; EvalErr[0]PerSample = 0.48203125; TotalTime = 0.0055s; SamplesPerSecond = 230921.9
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  41-  50]: SamplesSeen = 1280; TrainLossPerSample =  0.72144070; EvalErr[0]PerSample = 0.47968750; TotalTime = 0.0054s; SamplesPerSecond = 235944.7
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  51-  60]: SamplesSeen = 1280; TrainLossPerSample =  0.74117203; EvalErr[0]PerSample = 0.45781250; TotalTime = 0.0053s; SamplesPerSecond = 239476.1
04/22/2016 11:15:36:  Epoch[ 1 of 50]-Minibatch[  61-  70]: SamplesSeen = 1280; TrainLossPerSample =  0.73851624; EvalErr[0]PerSample = 0.45468750; TotalTime = 0.0052s; SamplesPerSecond = 244274.8
04/22/2016 11:15:36: Finished Epoch[ 1 of 50]: [Training Set] TrainLossPerSample = 0.73239092; TotalSamplesSeen = 10000; EvalErrPerSample = 0.4841; AvgLearningRatePerSample = 0.1; EpochTime=0.047491
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.1'

04/22/2016 11:15:36: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.49844599; EvalErr[0]PerSample = 0.27500000; TotalTime = 0.0056s; SamplesPerSecond = 230589.1
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.23827624; EvalErr[0]PerSample = 0.10078125; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.21230474; EvalErr[0]PerSample = 0.08828125; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.26566563; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.23675995; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 248206.3
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.22643766; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0051s; SamplesPerSecond = 249610.0
04/22/2016 11:15:36:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16871605; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36: Finished Epoch[ 2 of 50]: [Training Set] TrainLossPerSample = 0.2562446; TotalSamplesSeen = 20000; EvalErrPerSample = 0.1082; AvgLearningRatePerSample = 0.1; EpochTime=0.042354
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.2'

04/22/2016 11:15:36: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15800045; EvalErr[0]PerSample = 0.06171875; TotalTime = 0.0055s; SamplesPerSecond = 231339.2
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16581178; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247104.2
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.19208634; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0064s; SamplesPerSecond = 201131.4
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16155362; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0051s; SamplesPerSecond = 248543.7
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.20823994; EvalErr[0]PerSample = 0.10546875; TotalTime = 0.0052s; SamplesPerSecond = 247678.0
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15917044; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0052s; SamplesPerSecond = 246628.1
04/22/2016 11:15:36:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16028385; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0051s; SamplesPerSecond = 249366.8
04/22/2016 11:15:36: Finished Epoch[ 3 of 50]: [Training Set] TrainLossPerSample = 0.17244966; TotalSamplesSeen = 30000; EvalErrPerSample = 0.0772; AvgLearningRatePerSample = 0.1; EpochTime=0.044532
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.3'

04/22/2016 11:15:36: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.18641727; EvalErr[0]PerSample = 0.08984375; TotalTime = 0.0054s; SamplesPerSecond = 238361.3
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17437494; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0051s; SamplesPerSecond = 249366.8
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.14729924; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0052s; SamplesPerSecond = 247869.9
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16334558; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14964519; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 247630.1
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.18884621; EvalErr[0]PerSample = 0.09375000; TotalTime = 0.0051s; SamplesPerSecond = 249027.2
04/22/2016 11:15:36:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16661663; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0052s; SamplesPerSecond = 244929.2
04/22/2016 11:15:36: Finished Epoch[ 4 of 50]: [Training Set] TrainLossPerSample = 0.16787549; TotalSamplesSeen = 40000; EvalErrPerSample = 0.078; AvgLearningRatePerSample = 0.1; EpochTime=0.042311
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.4'

04/22/2016 11:15:36: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.14795903; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0054s; SamplesPerSecond = 235684.0
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.18887893; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0052s; SamplesPerSecond = 247247.4
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.19039135; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 246723.2
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16367836; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0051s; SamplesPerSecond = 248592.0
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14825487; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17402754; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247008.9
04/22/2016 11:15:36:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18850412; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0052s; SamplesPerSecond = 246295.9
04/22/2016 11:15:36: Finished Epoch[ 5 of 50]: [Training Set] TrainLossPerSample = 0.16812382; TotalSamplesSeen = 50000; EvalErrPerSample = 0.0764; AvgLearningRatePerSample = 0.1; EpochTime=0.043095
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.5'

04/22/2016 11:15:36: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16417081; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0055s; SamplesPerSecond = 234690.1
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15806549; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 246675.7
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15316281; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0051s; SamplesPerSecond = 248640.2
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16868725; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 244461.4
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16524410; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16858387; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0051s; SamplesPerSecond = 249221.2
04/22/2016 11:15:36:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15710440; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 247104.2
04/22/2016 11:15:36: Finished Epoch[ 6 of 50]: [Training Set] TrainLossPerSample = 0.16169873; TotalSamplesSeen = 60000; EvalErrPerSample = 0.0759; AvgLearningRatePerSample = 0.1; EpochTime=0.042416
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.6'

04/22/2016 11:15:36: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.18160670; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0053s; SamplesPerSecond = 242011.7
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.19635484; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0063s; SamplesPerSecond = 203530.0
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17201447; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16116471; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0051s; SamplesPerSecond = 250244.4
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14690962; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0051s; SamplesPerSecond = 249075.7
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17914429; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0051s; SamplesPerSecond = 249075.7
04/22/2016 11:15:36:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15242691; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:36: Finished Epoch[ 7 of 50]: [Training Set] TrainLossPerSample = 0.17052675; TotalSamplesSeen = 70000; EvalErrPerSample = 0.0778; AvgLearningRatePerSample = 0.1; EpochTime=0.043194
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.7'

04/22/2016 11:15:36: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.19076358; EvalErr[0]PerSample = 0.08906250; TotalTime = 0.0055s; SamplesPerSecond = 233534.0
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15753595; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16156242; EvalErr[0]PerSample = 0.06640625; TotalTime = 0.0051s; SamplesPerSecond = 249075.7
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15250697; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 247534.3
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16825061; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0052s; SamplesPerSecond = 248302.6
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.18632574; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 247534.3
04/22/2016 11:15:36:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14869471; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 248062.0
04/22/2016 11:15:36: Finished Epoch[ 8 of 50]: [Training Set] TrainLossPerSample = 0.16726316; TotalSamplesSeen = 80000; EvalErrPerSample = 0.0766; AvgLearningRatePerSample = 0.1; EpochTime=0.042422
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.8'

04/22/2016 11:15:36: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16929057; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0054s; SamplesPerSecond = 238183.8
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17313080; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0052s; SamplesPerSecond = 247104.2
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16014235; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 248302.6
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15436630; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 245540.0
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.13862023; EvalErr[0]PerSample = 0.05703125; TotalTime = 0.0051s; SamplesPerSecond = 249512.7
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17191706; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0052s; SamplesPerSecond = 247917.9
04/22/2016 11:15:36:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14892521; EvalErr[0]PerSample = 0.06406250; TotalTime = 0.0052s; SamplesPerSecond = 247199.7
04/22/2016 11:15:36: Finished Epoch[ 9 of 50]: [Training Set] TrainLossPerSample = 0.1602385; TotalSamplesSeen = 90000; EvalErrPerSample = 0.0745; AvgLearningRatePerSample = 0.1; EpochTime=0.042357
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.9'

04/22/2016 11:15:36: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15953542; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0054s; SamplesPerSecond = 238583.4
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16755599; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.14238110; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0051s; SamplesPerSecond = 249512.7
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17691975; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247247.4
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16566801; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 247917.9
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16127262; EvalErr[0]PerSample = 0.07968750; TotalTime = 0.0051s; SamplesPerSecond = 249512.7
04/22/2016 11:15:36:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14459457; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 245917.4
04/22/2016 11:15:36: Finished Epoch[10 of 50]: [Training Set] TrainLossPerSample = 0.15843969; TotalSamplesSeen = 100000; EvalErrPerSample = 0.0747; AvgLearningRatePerSample = 0.1; EpochTime=0.042269
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.10'

04/22/2016 11:15:36: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15813993; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0053s; SamplesPerSecond = 240601.5
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15605484; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0051s; SamplesPerSecond = 249951.2
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15871444; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0051s; SamplesPerSecond = 248640.2
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.18369932; EvalErr[0]PerSample = 0.09140625; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16956105; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0051s; SamplesPerSecond = 249951.2
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16034946; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:36:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15532818; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36: Finished Epoch[11 of 50]: [Training Set] TrainLossPerSample = 0.1619261; TotalSamplesSeen = 110000; EvalErrPerSample = 0.0764; AvgLearningRatePerSample = 0.1; EpochTime=0.042967
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.11'

04/22/2016 11:15:36: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.14863362; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0055s; SamplesPerSecond = 233321.2
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16842794; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 245351.7
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17496705; EvalErr[0]PerSample = 0.08281250; TotalTime = 0.0051s; SamplesPerSecond = 249075.7
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16903710; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 246675.7
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.19188952; EvalErr[0]PerSample = 0.08828125; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14883671; EvalErr[0]PerSample = 0.06640625; TotalTime = 0.0052s; SamplesPerSecond = 247247.4
04/22/2016 11:15:36:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16941423; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0051s; SamplesPerSecond = 248882.0
04/22/2016 11:15:36: Finished Epoch[12 of 50]: [Training Set] TrainLossPerSample = 0.16702578; TotalSamplesSeen = 120000; EvalErrPerSample = 0.077; AvgLearningRatePerSample = 0.1; EpochTime=0.042458
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.12'

04/22/2016 11:15:36: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15751876; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0054s; SamplesPerSecond = 238183.8
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15110375; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0051s; SamplesPerSecond = 248978.8
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16237354; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 247343.0
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16139441; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247534.3
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.18865647; EvalErr[0]PerSample = 0.09218750; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16029387; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:36:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18121376; EvalErr[0]PerSample = 0.08906250; TotalTime = 0.0052s; SamplesPerSecond = 247343.0
04/22/2016 11:15:36: Finished Epoch[13 of 50]: [Training Set] TrainLossPerSample = 0.16550038; TotalSamplesSeen = 130000; EvalErrPerSample = 0.0772; AvgLearningRatePerSample = 0.1; EpochTime=0.042793
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.13'

04/22/2016 11:15:36: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16697839; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0056s; SamplesPerSecond = 229144.3
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16038507; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 246533.1
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16519835; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0051s; SamplesPerSecond = 249075.7
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.14744382; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15347924; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0052s; SamplesPerSecond = 247152.0
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16583872; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 247630.1
04/22/2016 11:15:36:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16769333; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0051s; SamplesPerSecond = 249464.0
04/22/2016 11:15:36: Finished Epoch[14 of 50]: [Training Set] TrainLossPerSample = 0.16058113; TotalSamplesSeen = 140000; EvalErrPerSample = 0.0753; AvgLearningRatePerSample = 0.1; EpochTime=0.042626
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.14'

04/22/2016 11:15:36: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17504191; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0054s; SamplesPerSecond = 238095.2
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17398834; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0051s; SamplesPerSecond = 249610.0
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16190448; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 246913.6
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17221565; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.17401285; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0051s; SamplesPerSecond = 249951.2
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17121601; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0051s; SamplesPerSecond = 248688.6
04/22/2016 11:15:36:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17040396; EvalErr[0]PerSample = 0.07968750; TotalTime = 0.0052s; SamplesPerSecond = 248062.0
04/22/2016 11:15:36: Finished Epoch[15 of 50]: [Training Set] TrainLossPerSample = 0.17091887; TotalSamplesSeen = 150000; EvalErrPerSample = 0.0783; AvgLearningRatePerSample = 0.1; EpochTime=0.042175
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.15'

04/22/2016 11:15:36: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.14499781; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0054s; SamplesPerSecond = 238051.0
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17145016; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 247917.9
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16693320; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 248543.7
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.14426079; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0051s; SamplesPerSecond = 248640.2
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15098538; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0051s; SamplesPerSecond = 248592.0
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15499606; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 247869.9
04/22/2016 11:15:36:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15641975; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0051s; SamplesPerSecond = 249756.1
04/22/2016 11:15:36: Finished Epoch[16 of 50]: [Training Set] TrainLossPerSample = 0.15964783; TotalSamplesSeen = 160000; EvalErrPerSample = 0.0756; AvgLearningRatePerSample = 0.1; EpochTime=0.042771
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.16'

04/22/2016 11:15:36: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17199061; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0054s; SamplesPerSecond = 239028.9
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16243215; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0051s; SamplesPerSecond = 248543.7
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16780827; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0052s; SamplesPerSecond = 247438.6
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15655594; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0052s; SamplesPerSecond = 245917.4
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15865717; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0051s; SamplesPerSecond = 248785.2
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14919052; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0052s; SamplesPerSecond = 247965.9
04/22/2016 11:15:36:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15324907; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 247869.9
04/22/2016 11:15:36: Finished Epoch[17 of 50]: [Training Set] TrainLossPerSample = 0.15978615; TotalSamplesSeen = 170000; EvalErrPerSample = 0.0741; AvgLearningRatePerSample = 0.1; EpochTime=0.042277
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.17'

04/22/2016 11:15:36: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16007938; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0054s; SamplesPerSecond = 237653.2
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15282838; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 244788.7
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17086227; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0052s; SamplesPerSecond = 247295.2
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15249200; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0051s; SamplesPerSecond = 248882.0
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.18579073; EvalErr[0]PerSample = 0.08515625; TotalTime = 0.0052s; SamplesPerSecond = 248399.0
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16916332; EvalErr[0]PerSample = 0.08281250; TotalTime = 0.0052s; SamplesPerSecond = 245870.1
04/22/2016 11:15:36:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15036688; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0051s; SamplesPerSecond = 249658.7
04/22/2016 11:15:36: Finished Epoch[18 of 50]: [Training Set] TrainLossPerSample = 0.16232885; TotalSamplesSeen = 180000; EvalErrPerSample = 0.0754; AvgLearningRatePerSample = 0.1; EpochTime=0.042363
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.18'

04/22/2016 11:15:36: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.14655704; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0054s; SamplesPerSecond = 236817.8
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15965457; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 248110.1
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16810980; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247199.7
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17923822; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.18138480; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0051s; SamplesPerSecond = 249027.2
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.19831581; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0051s; SamplesPerSecond = 249221.2
04/22/2016 11:15:36:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15901518; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:36: Finished Epoch[19 of 50]: [Training Set] TrainLossPerSample = 0.16842527; TotalSamplesSeen = 190000; EvalErrPerSample = 0.078; AvgLearningRatePerSample = 0.1; EpochTime=0.042267
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.19'

04/22/2016 11:15:36: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16536107; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0055s; SamplesPerSecond = 234046.4
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.18725350; EvalErr[0]PerSample = 0.09609375; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17445228; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 247008.9
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15546021; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0051s; SamplesPerSecond = 248736.9
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16204357; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.18671103; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:36:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16987848; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0051s; SamplesPerSecond = 248978.8
04/22/2016 11:15:36: Finished Epoch[20 of 50]: [Training Set] TrainLossPerSample = 0.16896511; TotalSamplesSeen = 200000; EvalErrPerSample = 0.0784; AvgLearningRatePerSample = 0.1; EpochTime=0.042387
04/22/2016 11:15:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.20'

04/22/2016 11:15:36: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:36: Starting minibatch loop.
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16469026; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0055s; SamplesPerSecond = 232178.5
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15381482; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 247630.1
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15882838; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0051s; SamplesPerSecond = 248688.6
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16333499; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 247008.9
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.17477937; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 247869.9
04/22/2016 11:15:36:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15844307; EvalErr[0]PerSample = 0.06250000; TotalTime = 0.0051s; SamplesPerSecond = 249027.2
04/22/2016 11:15:37:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18186140; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 247056.6
04/22/2016 11:15:37: Finished Epoch[21 of 50]: [Training Set] TrainLossPerSample = 0.16533987; TotalSamplesSeen = 210000; EvalErrPerSample = 0.0757; AvgLearningRatePerSample = 0.1; EpochTime=0.042424
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.21'

04/22/2016 11:15:37: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.20349460; EvalErr[0]PerSample = 0.09765625; TotalTime = 0.0055s; SamplesPerSecond = 232642.7
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17329526; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 246913.6
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16117549; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 247199.7
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15503263; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0051s; SamplesPerSecond = 248592.0
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16139941; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 247152.0
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16247702; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 247247.4
04/22/2016 11:15:37:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17946978; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:37: Finished Epoch[22 of 50]: [Training Set] TrainLossPerSample = 0.16675658; TotalSamplesSeen = 220000; EvalErrPerSample = 0.0777; AvgLearningRatePerSample = 0.1; EpochTime=0.042449
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.22'

04/22/2016 11:15:37: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17159755; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0054s; SamplesPerSecond = 237124.9
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17114067; EvalErr[0]PerSample = 0.08281250; TotalTime = 0.0052s; SamplesPerSecond = 246485.7
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15244133; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 245257.7
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15626545; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16120481; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 248302.6
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14013510; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0051s; SamplesPerSecond = 249610.0
04/22/2016 11:15:37:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16929522; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 247917.9
04/22/2016 11:15:37: Finished Epoch[23 of 50]: [Training Set] TrainLossPerSample = 0.1596005; TotalSamplesSeen = 230000; EvalErrPerSample = 0.0749; AvgLearningRatePerSample = 0.1; EpochTime=0.042369
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.23'

04/22/2016 11:15:37: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17182534; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0055s; SamplesPerSecond = 234862.4
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15354180; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16197517; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247773.9
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16589236; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0051s; SamplesPerSecond = 248833.6
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16722527; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0051s; SamplesPerSecond = 248882.0
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17564621; EvalErr[0]PerSample = 0.08515625; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:37:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16375523; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 248014.0
04/22/2016 11:15:37: Finished Epoch[24 of 50]: [Training Set] TrainLossPerSample = 0.1671468; TotalSamplesSeen = 240000; EvalErrPerSample = 0.0768; AvgLearningRatePerSample = 0.1; EpochTime=0.042976
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.24'

04/22/2016 11:15:37: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17995144; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0054s; SamplesPerSecond = 237918.2
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.18855680; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 247152.0
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16692853; EvalErr[0]PerSample = 0.07968750; TotalTime = 0.0051s; SamplesPerSecond = 249707.4
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17160010; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15487242; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 248254.5
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14489584; EvalErr[0]PerSample = 0.06406250; TotalTime = 0.0051s; SamplesPerSecond = 249951.2
04/22/2016 11:15:37:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16311197; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 248110.1
04/22/2016 11:15:37: Finished Epoch[25 of 50]: [Training Set] TrainLossPerSample = 0.1676745; TotalSamplesSeen = 250000; EvalErrPerSample = 0.0777; AvgLearningRatePerSample = 0.1; EpochTime=0.042988
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.25'

04/22/2016 11:15:37: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16878680; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0054s; SamplesPerSecond = 238006.7
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15142335; EvalErr[0]PerSample = 0.06640625; TotalTime = 0.0052s; SamplesPerSecond = 247056.6
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15124261; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 247678.0
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15940924; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0052s; SamplesPerSecond = 247152.0
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.17065425; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0051s; SamplesPerSecond = 249366.8
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14535627; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:37:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17644196; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0052s; SamplesPerSecond = 247104.2
04/22/2016 11:15:37: Finished Epoch[26 of 50]: [Training Set] TrainLossPerSample = 0.15937399; TotalSamplesSeen = 260000; EvalErrPerSample = 0.0744; AvgLearningRatePerSample = 0.1; EpochTime=0.042434
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.26'

04/22/2016 11:15:37: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15709606; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0055s; SamplesPerSecond = 234389.3
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16543278; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247726.0
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15277243; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0051s; SamplesPerSecond = 250000.0
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16587291; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15222979; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 247630.1
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15051160; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:37:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18173809; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 247199.7
04/22/2016 11:15:37: Finished Epoch[27 of 50]: [Training Set] TrainLossPerSample = 0.1583038; TotalSamplesSeen = 270000; EvalErrPerSample = 0.0753; AvgLearningRatePerSample = 0.1; EpochTime=0.042424
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.27'

04/22/2016 11:15:37: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16907725; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0054s; SamplesPerSecond = 237741.5
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.14707675; EvalErr[0]PerSample = 0.06328125; TotalTime = 0.0051s; SamplesPerSecond = 249318.3
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.14986844; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 246343.3
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16217022; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.18148379; EvalErr[0]PerSample = 0.08906250; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15600395; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:37:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16555977; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 247965.9
04/22/2016 11:15:37: Finished Epoch[28 of 50]: [Training Set] TrainLossPerSample = 0.16259104; TotalSamplesSeen = 280000; EvalErrPerSample = 0.0756; AvgLearningRatePerSample = 0.1; EpochTime=0.042294
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.28'

04/22/2016 11:15:37: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16562409; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0054s; SamplesPerSecond = 238051.0
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15941448; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 248254.5
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16366005; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0051s; SamplesPerSecond = 249027.2
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15629354; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 247486.5
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14837217; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15770683; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 245304.7
04/22/2016 11:15:37:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15916605; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0051s; SamplesPerSecond = 248833.6
04/22/2016 11:15:37: Finished Epoch[29 of 50]: [Training Set] TrainLossPerSample = 0.15779647; TotalSamplesSeen = 290000; EvalErrPerSample = 0.0734; AvgLearningRatePerSample = 0.1; EpochTime=0.042302
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.29'

04/22/2016 11:15:37: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.14879414; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0054s; SamplesPerSecond = 235423.9
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15640088; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 248447.2
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.18904817; EvalErr[0]PerSample = 0.08515625; TotalTime = 0.0052s; SamplesPerSecond = 247438.6
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.14199157; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 247295.2
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14786634; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0051s; SamplesPerSecond = 249124.2
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16597719; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0052s; SamplesPerSecond = 246248.6
04/22/2016 11:15:37:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16080685; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 247343.0
04/22/2016 11:15:37: Finished Epoch[30 of 50]: [Training Set] TrainLossPerSample = 0.1590681; TotalSamplesSeen = 300000; EvalErrPerSample = 0.0757; AvgLearningRatePerSample = 0.1; EpochTime=0.042369
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.30'

04/22/2016 11:15:37: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16275747; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0054s; SamplesPerSecond = 237520.9
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17017744; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 247390.8
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.14321690; EvalErr[0]PerSample = 0.06328125; TotalTime = 0.0052s; SamplesPerSecond = 247104.2
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15120192; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15285535; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 247534.3
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.13534746; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:37:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17624168; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0051s; SamplesPerSecond = 249172.7
04/22/2016 11:15:37: Finished Epoch[31 of 50]: [Training Set] TrainLossPerSample = 0.15980447; TotalSamplesSeen = 310000; EvalErrPerSample = 0.0737; AvgLearningRatePerSample = 0.1; EpochTime=0.042311
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.31'

04/22/2016 11:15:37: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16198603; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0055s; SamplesPerSecond = 233875.4
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16215128; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 248350.8
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.13372493; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0052s; SamplesPerSecond = 247438.6
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16426897; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 248399.0
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16832581; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 246201.2
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16835799; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 248206.3
04/22/2016 11:15:37:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14903240; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0052s; SamplesPerSecond = 248014.0
04/22/2016 11:15:37: Finished Epoch[32 of 50]: [Training Set] TrainLossPerSample = 0.16206069; TotalSamplesSeen = 320000; EvalErrPerSample = 0.0747; AvgLearningRatePerSample = 0.1; EpochTime=0.042384
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.32'

04/22/2016 11:15:37: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17260246; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0054s; SamplesPerSecond = 237962.4
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15036039; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0052s; SamplesPerSecond = 247582.2
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.14416060; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0052s; SamplesPerSecond = 247821.9
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16257310; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0051s; SamplesPerSecond = 249561.3
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16877379; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0051s; SamplesPerSecond = 248785.2
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15273433; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 247965.9
04/22/2016 11:15:37:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17888365; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0051s; SamplesPerSecond = 250146.6
04/22/2016 11:15:37: Finished Epoch[33 of 50]: [Training Set] TrainLossPerSample = 0.16180493; TotalSamplesSeen = 330000; EvalErrPerSample = 0.0754; AvgLearningRatePerSample = 0.1; EpochTime=0.042721
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.33'

04/22/2016 11:15:37: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17212042; EvalErr[0]PerSample = 0.08437500; TotalTime = 0.0100s; SamplesPerSecond = 128449.6
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16251820; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0083s; SamplesPerSecond = 155095.1
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16373570; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0079s; SamplesPerSecond = 161534.6
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15235853; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0079s; SamplesPerSecond = 162684.3
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14773169; EvalErr[0]PerSample = 0.06484375; TotalTime = 0.0075s; SamplesPerSecond = 169896.5
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15427613; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0075s; SamplesPerSecond = 170462.1
04/22/2016 11:15:37:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15895214; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0073s; SamplesPerSecond = 174815.6
04/22/2016 11:15:37: Finished Epoch[34 of 50]: [Training Set] TrainLossPerSample = 0.15999508; TotalSamplesSeen = 340000; EvalErrPerSample = 0.0751; AvgLearningRatePerSample = 0.1; EpochTime=0.065596
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.34'

04/22/2016 11:15:37: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16768734; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0072s; SamplesPerSecond = 178845.9
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15872080; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0068s; SamplesPerSecond = 189405.1
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16511321; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0065s; SamplesPerSecond = 195988.4
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15483818; EvalErr[0]PerSample = 0.07109375; TotalTime = 0.0064s; SamplesPerSecond = 199968.8
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14570861; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0063s; SamplesPerSecond = 204114.2
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15019670; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0062s; SamplesPerSecond = 207321.0
04/22/2016 11:15:37:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18149834; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0060s; SamplesPerSecond = 212272.0
04/22/2016 11:15:37: Finished Epoch[35 of 50]: [Training Set] TrainLossPerSample = 0.16064935; TotalSamplesSeen = 350000; EvalErrPerSample = 0.0761; AvgLearningRatePerSample = 0.1; EpochTime=0.053445
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.35'

04/22/2016 11:15:37: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17114046; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0062s; SamplesPerSecond = 205721.6
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15853362; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0058s; SamplesPerSecond = 222106.5
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16492016; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0057s; SamplesPerSecond = 225988.7
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16080680; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0056s; SamplesPerSecond = 226669.0
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15284748; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0055s; SamplesPerSecond = 232094.3
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15469093; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0054s; SamplesPerSecond = 237918.2
04/22/2016 11:15:37:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18092909; EvalErr[0]PerSample = 0.08437500; TotalTime = 0.0054s; SamplesPerSecond = 237300.7
04/22/2016 11:15:37: Finished Epoch[36 of 50]: [Training Set] TrainLossPerSample = 0.16307072; TotalSamplesSeen = 360000; EvalErrPerSample = 0.0769; AvgLearningRatePerSample = 0.1; EpochTime=0.04702
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.36'

04/22/2016 11:15:37: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15121933; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0055s; SamplesPerSecond = 230880.2
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15874640; EvalErr[0]PerSample = 0.07968750; TotalTime = 0.0053s; SamplesPerSecond = 242976.5
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17776811; EvalErr[0]PerSample = 0.08671875; TotalTime = 0.0053s; SamplesPerSecond = 241737.5
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15243282; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0053s; SamplesPerSecond = 242930.3
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15466061; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0053s; SamplesPerSecond = 240511.1
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14456711; EvalErr[0]PerSample = 0.06796875; TotalTime = 0.0053s; SamplesPerSecond = 241281.8
04/22/2016 11:15:37:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16275959; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 244274.8
04/22/2016 11:15:37: Finished Epoch[37 of 50]: [Training Set] TrainLossPerSample = 0.15827073; TotalSamplesSeen = 370000; EvalErrPerSample = 0.0747; AvgLearningRatePerSample = 0.1; EpochTime=0.043278
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.37'

04/22/2016 11:15:37: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.16772085; EvalErr[0]PerSample = 0.07968750; TotalTime = 0.0055s; SamplesPerSecond = 232642.7
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15543104; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0053s; SamplesPerSecond = 242240.7
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15747359; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 244088.5
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.18036132; EvalErr[0]PerSample = 0.08437500; TotalTime = 0.0053s; SamplesPerSecond = 243068.7
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16553802; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0053s; SamplesPerSecond = 242240.7
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16498785; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 244648.3
04/22/2016 11:15:37:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14760456; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 244835.5
04/22/2016 11:15:37: Finished Epoch[38 of 50]: [Training Set] TrainLossPerSample = 0.16437142; TotalSamplesSeen = 380000; EvalErrPerSample = 0.0769; AvgLearningRatePerSample = 0.1; EpochTime=0.043113
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.38'

04/22/2016 11:15:37: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15486621; EvalErr[0]PerSample = 0.06406250; TotalTime = 0.0055s; SamplesPerSecond = 234690.1
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17947727; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0053s; SamplesPerSecond = 242103.3
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17070036; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0053s; SamplesPerSecond = 241418.3
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17012653; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 243856.0
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14479184; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0053s; SamplesPerSecond = 241600.6
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.13912868; EvalErr[0]PerSample = 0.06171875; TotalTime = 0.0053s; SamplesPerSecond = 242470.2
04/22/2016 11:15:37:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15967236; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0053s; SamplesPerSecond = 242149.1
04/22/2016 11:15:37: Finished Epoch[39 of 50]: [Training Set] TrainLossPerSample = 0.16386038; TotalSamplesSeen = 390000; EvalErrPerSample = 0.0755; AvgLearningRatePerSample = 0.1; EpochTime=0.04321
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.39'

04/22/2016 11:15:37: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17116035; EvalErr[0]PerSample = 0.08046875; TotalTime = 0.0055s; SamplesPerSecond = 233704.6
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15966755; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0053s; SamplesPerSecond = 241874.5
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15952749; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 244368.1
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15408745; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0053s; SamplesPerSecond = 243207.3
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15742254; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0053s; SamplesPerSecond = 243114.9
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16165428; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 245964.6
04/22/2016 11:15:37:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18436928; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0053s; SamplesPerSecond = 242700.0
04/22/2016 11:15:37: Finished Epoch[40 of 50]: [Training Set] TrainLossPerSample = 0.16481317; TotalSamplesSeen = 400000; EvalErrPerSample = 0.0757; AvgLearningRatePerSample = 0.1; EpochTime=0.043019
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.40'

04/22/2016 11:15:37: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17456948; EvalErr[0]PerSample = 0.08281250; TotalTime = 0.0055s; SamplesPerSecond = 232769.6
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.14992534; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0053s; SamplesPerSecond = 242930.3
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16370718; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 244181.6
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.16085892; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 243995.4
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15773916; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 246723.2
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14436560; EvalErr[0]PerSample = 0.06171875; TotalTime = 0.0052s; SamplesPerSecond = 244601.6
04/22/2016 11:15:37:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15339127; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 244882.3
04/22/2016 11:15:37: Finished Epoch[41 of 50]: [Training Set] TrainLossPerSample = 0.15843993; TotalSamplesSeen = 410000; EvalErrPerSample = 0.0738; AvgLearningRatePerSample = 0.1; EpochTime=0.04288
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.41'

04/22/2016 11:15:37: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17765872; EvalErr[0]PerSample = 0.09062500; TotalTime = 0.0055s; SamplesPerSecond = 233747.3
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15345802; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0053s; SamplesPerSecond = 243577.5
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15648363; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0052s; SamplesPerSecond = 245257.7
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15764866; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 244181.6
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.16663527; EvalErr[0]PerSample = 0.07812500; TotalTime = 0.0052s; SamplesPerSecond = 244601.6
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14366312; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 246201.2
04/22/2016 11:15:37:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.15641041; EvalErr[0]PerSample = 0.07656250; TotalTime = 0.0052s; SamplesPerSecond = 244135.0
04/22/2016 11:15:37: Finished Epoch[42 of 50]: [Training Set] TrainLossPerSample = 0.15860309; TotalSamplesSeen = 420000; EvalErrPerSample = 0.0762; AvgLearningRatePerSample = 0.1; EpochTime=0.042871
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.42'

04/22/2016 11:15:37: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.15629978; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0055s; SamplesPerSecond = 232558.1
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15308681; EvalErr[0]PerSample = 0.07578125; TotalTime = 0.0052s; SamplesPerSecond = 244882.3
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.13974714; EvalErr[0]PerSample = 0.06171875; TotalTime = 0.0052s; SamplesPerSecond = 246153.8
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15581884; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 244554.8
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.14598875; EvalErr[0]PerSample = 0.06562500; TotalTime = 0.0052s; SamplesPerSecond = 246201.2
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.18109012; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 244741.9
04/22/2016 11:15:37:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.17168808; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0053s; SamplesPerSecond = 243484.9
04/22/2016 11:15:37: Finished Epoch[43 of 50]: [Training Set] TrainLossPerSample = 0.15814011; TotalSamplesSeen = 430000; EvalErrPerSample = 0.0736; AvgLearningRatePerSample = 0.1; EpochTime=0.04285
04/22/2016 11:15:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.43'

04/22/2016 11:15:37: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:37: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17231215; EvalErr[0]PerSample = 0.08828125; TotalTime = 0.0055s; SamplesPerSecond = 233151.2
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.13793191; EvalErr[0]PerSample = 0.06171875; TotalTime = 0.0052s; SamplesPerSecond = 244274.8
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16530793; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0052s; SamplesPerSecond = 245822.9
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.19532490; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0053s; SamplesPerSecond = 243577.5
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.17846708; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 244368.1
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.21160440; EvalErr[0]PerSample = 0.09375000; TotalTime = 0.0052s; SamplesPerSecond = 246390.8
04/22/2016 11:15:38:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18801451; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 244554.8
04/22/2016 11:15:38: Finished Epoch[44 of 50]: [Training Set] TrainLossPerSample = 0.17975637; TotalSamplesSeen = 440000; EvalErrPerSample = 0.0819; AvgLearningRatePerSample = 0.1; EpochTime=0.043462
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.44'

04/22/2016 11:15:38: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.19800924; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0055s; SamplesPerSecond = 234690.1
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15382909; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 245870.1
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16011508; EvalErr[0]PerSample = 0.06953125; TotalTime = 0.0052s; SamplesPerSecond = 244788.7
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17285686; EvalErr[0]PerSample = 0.08515625; TotalTime = 0.0052s; SamplesPerSecond = 244228.2
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.12871933; EvalErr[0]PerSample = 0.05546875; TotalTime = 0.0052s; SamplesPerSecond = 245775.7
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.19098673; EvalErr[0]PerSample = 0.09218750; TotalTime = 0.0052s; SamplesPerSecond = 244088.5
04/22/2016 11:15:38:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.18352175; EvalErr[0]PerSample = 0.08750000; TotalTime = 0.0052s; SamplesPerSecond = 245398.8
04/22/2016 11:15:38: Finished Epoch[45 of 50]: [Training Set] TrainLossPerSample = 0.16838311; TotalSamplesSeen = 450000; EvalErrPerSample = 0.077; AvgLearningRatePerSample = 0.1; EpochTime=0.042784
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.45'

04/22/2016 11:15:38: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17409596; EvalErr[0]PerSample = 0.08281250; TotalTime = 0.0055s; SamplesPerSecond = 234518.1
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.15440207; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0053s; SamplesPerSecond = 243716.7
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16372375; EvalErr[0]PerSample = 0.07421875; TotalTime = 0.0052s; SamplesPerSecond = 245257.7
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17626610; EvalErr[0]PerSample = 0.07734375; TotalTime = 0.0052s; SamplesPerSecond = 243995.4
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.19316640; EvalErr[0]PerSample = 0.08984375; TotalTime = 0.0052s; SamplesPerSecond = 244135.0
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.16905041; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 244321.4
04/22/2016 11:15:38:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16094189; EvalErr[0]PerSample = 0.07500000; TotalTime = 0.0052s; SamplesPerSecond = 246106.5
04/22/2016 11:15:38: Finished Epoch[46 of 50]: [Training Set] TrainLossPerSample = 0.1703506; TotalSamplesSeen = 460000; EvalErrPerSample = 0.08; AvgLearningRatePerSample = 0.1; EpochTime=0.042866
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.46'

04/22/2016 11:15:38: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.19717929; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0054s; SamplesPerSecond = 235078.1
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.17599423; EvalErr[0]PerSample = 0.08437500; TotalTime = 0.0052s; SamplesPerSecond = 244976.1
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16111016; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 244135.0
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.17828102; EvalErr[0]PerSample = 0.07890625; TotalTime = 0.0052s; SamplesPerSecond = 243902.4
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.17307181; EvalErr[0]PerSample = 0.07343750; TotalTime = 0.0052s; SamplesPerSecond = 245398.8
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.15202847; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 245257.7
04/22/2016 11:15:38:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14770584; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 244695.1
04/22/2016 11:15:38: Finished Epoch[47 of 50]: [Training Set] TrainLossPerSample = 0.16891559; TotalSamplesSeen = 470000; EvalErrPerSample = 0.0765; AvgLearningRatePerSample = 0.1; EpochTime=0.042824
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.47'

04/22/2016 11:15:38: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.18937269; EvalErr[0]PerSample = 0.08828125; TotalTime = 0.0055s; SamplesPerSecond = 234475.2
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16697210; EvalErr[0]PerSample = 0.07265625; TotalTime = 0.0052s; SamplesPerSecond = 244368.1
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.16790352; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0052s; SamplesPerSecond = 245069.9
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15334334; EvalErr[0]PerSample = 0.06718750; TotalTime = 0.0052s; SamplesPerSecond = 246390.8
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.13439164; EvalErr[0]PerSample = 0.06015625; TotalTime = 0.0052s; SamplesPerSecond = 245351.7
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.17633085; EvalErr[0]PerSample = 0.09062500; TotalTime = 0.0052s; SamplesPerSecond = 245917.4
04/22/2016 11:15:38:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16360855; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0052s; SamplesPerSecond = 246390.8
04/22/2016 11:15:38: Finished Epoch[48 of 50]: [Training Set] TrainLossPerSample = 0.16220254; TotalSamplesSeen = 480000; EvalErrPerSample = 0.0766; AvgLearningRatePerSample = 0.1; EpochTime=0.043178
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.48'

04/22/2016 11:15:38: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17351890; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0055s; SamplesPerSecond = 231590.4
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16539621; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 246248.6
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.17113476; EvalErr[0]PerSample = 0.08203125; TotalTime = 0.0052s; SamplesPerSecond = 245775.7
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15255365; EvalErr[0]PerSample = 0.06250000; TotalTime = 0.0052s; SamplesPerSecond = 244695.1
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.18179183; EvalErr[0]PerSample = 0.08593750; TotalTime = 0.0052s; SamplesPerSecond = 246818.4
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14414062; EvalErr[0]PerSample = 0.05937500; TotalTime = 0.0052s; SamplesPerSecond = 244882.3
04/22/2016 11:15:38:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.16890469; EvalErr[0]PerSample = 0.08125000; TotalTime = 0.0052s; SamplesPerSecond = 245398.8
04/22/2016 11:15:38: Finished Epoch[49 of 50]: [Training Set] TrainLossPerSample = 0.16371609; TotalSamplesSeen = 490000; EvalErrPerSample = 0.0756; AvgLearningRatePerSample = 0.1; EpochTime=0.042849
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.49'

04/22/2016 11:15:38: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:38: Starting minibatch loop.
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: SamplesSeen = 1280; TrainLossPerSample =  0.17541748; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.0057s; SamplesPerSecond = 224995.6
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: SamplesSeen = 1280; TrainLossPerSample =  0.16571561; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 243856.0
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: SamplesSeen = 1280; TrainLossPerSample =  0.15297840; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0052s; SamplesPerSecond = 244181.6
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: SamplesSeen = 1280; TrainLossPerSample =  0.15474606; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 246485.7
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: SamplesSeen = 1280; TrainLossPerSample =  0.15424123; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 245210.7
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: SamplesSeen = 1280; TrainLossPerSample =  0.14947758; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0052s; SamplesPerSecond = 244835.5
04/22/2016 11:15:38:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: SamplesSeen = 1280; TrainLossPerSample =  0.14548941; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0052s; SamplesPerSecond = 246485.7
04/22/2016 11:15:38: Finished Epoch[50 of 50]: [Training Set] TrainLossPerSample = 0.15954731; TotalSamplesSeen = 500000; EvalErrPerSample = 0.0737; AvgLearningRatePerSample = 0.1; EpochTime=0.044443
04/22/2016 11:15:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn'
04/22/2016 11:15:38: CNTKCommandTrainEnd: Simple_Demo

04/22/2016 11:15:38: Action "train" complete.


04/22/2016 11:15:38: ##############################################################################
04/22/2016 11:15:38: #                                                                            #
04/22/2016 11:15:38: # Action "write"                                                             #
04/22/2016 11:15:38: #                                                                            #
04/22/2016 11:15:38: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.
Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

04/22/2016 11:15:38: Action "write" complete.

04/22/2016 11:15:38: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/alrezni/src/cntk_git/build/release/bin/cntk configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple/Speech_Simple.cntk currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Apr 22 2016 10:15:37
		Last modified date: Tue Apr  5 16:01:37 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: acml
		CUDA_PATH: /usr/local/cuda-7.0
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: alrezni/examples_text
		Build SHA1: 6a74de8e569af56e61a14d762716930c397b5c90
		Built by alrezni on atleneu04
		Build Path: /home/alrezni/src/cntk_git
-------------------------------------------------------------------
Changed current directory to /home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
04/22/2016 11:15:38: -------------------------------------------------------------------
04/22/2016 11:15:38: Build info: 

04/22/2016 11:15:38: 		Built time: Apr 22 2016 10:15:37
04/22/2016 11:15:38: 		Last modified date: Tue Apr  5 16:01:37 2016
04/22/2016 11:15:38: 		Build type: release
04/22/2016 11:15:38: 		Build target: GPU
04/22/2016 11:15:38: 		With 1bit-SGD: no
04/22/2016 11:15:38: 		Math lib: acml
04/22/2016 11:15:38: 		CUDA_PATH: /usr/local/cuda-7.0
04/22/2016 11:15:38: 		CUB_PATH: /usr/local/cub-1.4.1
04/22/2016 11:15:38: 		CUDNN_PATH: /usr/local/cudnn-4.0
04/22/2016 11:15:38: 		Build Branch: alrezni/examples_text
04/22/2016 11:15:38: 		Build SHA1: 6a74de8e569af56e61a14d762716930c397b5c90
04/22/2016 11:15:38: 		Built by alrezni on atleneu04
04/22/2016 11:15:38: 		Build Path: /home/alrezni/src/cntk_git
04/22/2016 11:15:38: -------------------------------------------------------------------

04/22/2016 11:15:38: Running on localhost at 2016/04/22 11:15:38
04/22/2016 11:15:38: Command line: 
/home/alrezni/src/cntk_git/build/release/bin/cntk  configFile=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple/Speech_Simple.cntk  currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu  DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple  OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu  DeviceId=0  timestamping=true  makeMode=true



04/22/2016 11:15:38: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
04/22/2016 11:15:38: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=$DataDir$/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=$DataDir$/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

04/22/2016 11:15:38: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

04/22/2016 11:15:38: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
04/22/2016 11:15:38: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

04/22/2016 11:15:38: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

04/22/2016 11:15:38: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: Speech_Simple.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: Speech_Simple.cntk:ConfigDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/CNTKTextFormatReader/Speech/Simple
configparameters: Speech_Simple.cntk:currentDirectory=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
configparameters: Speech_Simple.cntk:DataDir=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data
configparameters: Speech_Simple.cntk:deviceId=0
configparameters: Speech_Simple.cntk:DeviceNumber=-1
configparameters: Speech_Simple.cntk:makeMode=true
configparameters: Speech_Simple.cntk:modelPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
configparameters: Speech_Simple.cntk:OutputDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
configparameters: Speech_Simple.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: Speech_Simple.cntk:precision=float
configparameters: Speech_Simple.cntk:RunDir=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu
configparameters: Speech_Simple.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
]

configparameters: Speech_Simple.cntk:Simple_Demo_Output=[
    action=write
    reader=[
      readerType=CNTKTextFormatReader
      file=/home/alrezni/src/cntk_git/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
      input = [
        features = [
dim = 2 
          format = "dense" 
        ]
        labels = [
dim = 2 
          format = "dense"
        ]
      ]
    ]
outputPath=/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: Speech_Simple.cntk:timestamping=true
configparameters: Speech_Simple.cntk:traceLevel=1
04/22/2016 11:15:38: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
04/22/2016 11:15:38: Commands: Simple_Demo Simple_Demo_Output
04/22/2016 11:15:38: Precision = "float"
04/22/2016 11:15:38: CNTKModelPath: /tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn
04/22/2016 11:15:38: CNTKCommandTrainInfo: Simple_Demo : 50
04/22/2016 11:15:38: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

04/22/2016 11:15:38: ##############################################################################
04/22/2016 11:15:38: #                                                                            #
04/22/2016 11:15:38: # Action "train"                                                             #
04/22/2016 11:15:38: #                                                                            #
04/22/2016 11:15:38: ##############################################################################

04/22/2016 11:15:38: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

04/22/2016 11:15:38: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

04/22/2016 11:15:39: Loaded model with 25 nodes on GPU 0.

04/22/2016 11:15:39: Training criterion node(s):
04/22/2016 11:15:39: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

04/22/2016 11:15:39: Evaluation criterion node(s):

04/22/2016 11:15:39: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.
04/22/2016 11:15:39: No PreCompute nodes found, skipping PreCompute step.

04/22/2016 11:15:39: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples

04/22/2016 11:15:39: Starting minibatch loop.
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: SamplesSeen = 1280; TrainLossPerSample =  0.17541748; EvalErr[0]PerSample = 0.08359375; TotalTime = 0.1487s; SamplesPerSecond = 8609.6
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: SamplesSeen = 1280; TrainLossPerSample =  0.16571561; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0058s; SamplesPerSecond = 219667.1
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: SamplesSeen = 1280; TrainLossPerSample =  0.15297840; EvalErr[0]PerSample = 0.06875000; TotalTime = 0.0057s; SamplesPerSecond = 226468.5
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: SamplesSeen = 1280; TrainLossPerSample =  0.15474606; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0057s; SamplesPerSecond = 224443.3
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: SamplesSeen = 1280; TrainLossPerSample =  0.15424123; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0055s; SamplesPerSecond = 230963.6
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: SamplesSeen = 1280; TrainLossPerSample =  0.14947758; EvalErr[0]PerSample = 0.07031250; TotalTime = 0.0056s; SamplesPerSecond = 230091.7
04/22/2016 11:15:39:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: SamplesSeen = 1280; TrainLossPerSample =  0.14548941; EvalErr[0]PerSample = 0.07187500; TotalTime = 0.0054s; SamplesPerSecond = 236031.7
04/22/2016 11:15:39: Finished Epoch[50 of 50]: [Training Set] TrainLossPerSample = 0.15954731; TotalSamplesSeen = 500000; EvalErrPerSample = 0.0737; AvgLearningRatePerSample = 0.1; EpochTime=0.190199
04/22/2016 11:15:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/models/simple.dnn'
04/22/2016 11:15:39: CNTKCommandTrainEnd: Simple_Demo

04/22/2016 11:15:39: Action "train" complete.


04/22/2016 11:15:39: ##############################################################################
04/22/2016 11:15:39: #                                                                            #
04/22/2016 11:15:39: # Action "write"                                                             #
04/22/2016 11:15:39: #                                                                            #
04/22/2016 11:15:39: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.
Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160422111509.401111/CNTKTextFormatReader/Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

04/22/2016 11:15:39: Action "write" complete.

04/22/2016 11:15:39: __COMPLETED__