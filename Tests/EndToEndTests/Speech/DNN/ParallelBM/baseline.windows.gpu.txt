=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 2 D:\work\Program\Code\local-src\CNTK-public\CNTK-github\x64\debug\cntk.exe configFile=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu DeviceId=0 timestamping=true numCPUThreads=4 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Apr 28 2016 15:12:06
		Last modified date: Mon Apr 11 11:57:54 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\work\Program\Code\src\CUB
		CUDNN_PATH: D:\work\Program\Code\src\cuDNN\cuda
		Build Branch: erw/bm_rc
		Build SHA1: e316467a84d39f17603f4799a8458e8b5eb28a85 (modified)
		Built by erw on 7253-Wang
		Build Path: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 28 2016 15:12:06
		Last modified date: Mon Apr 11 11:57:54 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: D:\work\Program\Code\src\CUB
		CUDNN_PATH: D:\work\Program\Code\src\cuDNN\cuda
		Build Branch: erw/bm_rc
		Build SHA1: e316467a84d39f17603f4799a8458e8b5eb28a85 (modified)
		Built by erw on 7253-Wang
		Build Path: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
MPI Rank 0: 04/28/2016 15:41:55: Redirecting stderr to file C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr_speechTrain.logrank0
MPI Rank 0: 04/28/2016 15:41:55: -------------------------------------------------------------------
MPI Rank 0: 04/28/2016 15:41:55: Build info: 
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: 		Built time: Apr 28 2016 15:12:06
MPI Rank 0: 04/28/2016 15:41:55: 		Last modified date: Mon Apr 11 11:57:54 2016
MPI Rank 0: 04/28/2016 15:41:55: 		Build type: Debug
MPI Rank 0: 04/28/2016 15:41:55: 		Build target: GPU
MPI Rank 0: 04/28/2016 15:41:55: 		With 1bit-SGD: yes
MPI Rank 0: 04/28/2016 15:41:55: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 0: 04/28/2016 15:41:55: 		CUB_PATH: D:\work\Program\Code\src\CUB
MPI Rank 0: 04/28/2016 15:41:55: 		CUDNN_PATH: D:\work\Program\Code\src\cuDNN\cuda
MPI Rank 0: 04/28/2016 15:41:55: 		Build Branch: erw/bm_rc
MPI Rank 0: 04/28/2016 15:41:55: 		Build SHA1: e316467a84d39f17603f4799a8458e8b5eb28a85 (modified)
MPI Rank 0: 04/28/2016 15:41:55: 		Built by erw on 7253-Wang
MPI Rank 0: 04/28/2016 15:41:55: 		Build Path: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Source\CNTK\
MPI Rank 0: 04/28/2016 15:41:55: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: Running on 7253-Wang at 2016/04/28 15:41:55
MPI Rank 0: 04/28/2016 15:41:55: Command line: 
MPI Rank 0: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\x64\debug\cntk.exe  configFile=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk  currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu  DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=4  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/28/2016 15:41:55: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 syncPeriod=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=4
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/28/2016 15:41:55: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = 0
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 syncPeriod=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=4
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=0
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=4
MPI Rank 0: configparameters: cntk.cntk:OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 syncPeriod=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 04/28/2016 15:41:55: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 04/28/2016 15:41:55: Commands: speechTrain
MPI Rank 0: 04/28/2016 15:41:55: Precision = "double"
MPI Rank 0: 04/28/2016 15:41:55: Using 4 CPU threads.
MPI Rank 0: 04/28/2016 15:41:55: CNTKModelPath: C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn
MPI Rank 0: 04/28/2016 15:41:55: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 04/28/2016 15:41:55: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: ##############################################################################
MPI Rank 0: 04/28/2016 15:41:55: #                                                                            #
MPI Rank 0: 04/28/2016 15:41:55: # Action "train"                                                             #
MPI Rank 0: 04/28/2016 15:41:55: #                                                                            #
MPI Rank 0: 04/28/2016 15:41:55: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:55: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 948 entries
MPI Rank 0: total 132 state names in state list D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:57: Creating virgin network.
MPI Rank 0: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: Created model with 25 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: Training criterion node(s):
MPI Rank 0: 04/28/2016 15:41:59: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:41:59: 	MeanOfFeatures = Mean()
MPI Rank 0: 04/28/2016 15:41:59: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 04/28/2016 15:41:59: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:30: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:31: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:31: Starting minibatch loop.
MPI Rank 0: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: SamplesSeen = 192; TrainLossPerSample =  4.59555827; EvalErr[0]PerSample = 0.95312500; TotalTime = 0.1519s; SamplesPerSecond = 1264.3
MPI Rank 0: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: SamplesSeen = 192; TrainLossPerSample =  4.63574590; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1268s; SamplesPerSecond = 1513.7
MPI Rank 0: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: SamplesSeen = 192; TrainLossPerSample =  4.40475736; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1283s; SamplesPerSecond = 1496.7
MPI Rank 0: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: SamplesSeen = 192; TrainLossPerSample =  4.37017519; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1254s; SamplesPerSecond = 1531.5
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: SamplesSeen = 192; TrainLossPerSample =  4.34202026; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1254s; SamplesPerSecond = 1531.0
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.63%]: SamplesSeen = 192; TrainLossPerSample =  4.05288419; EvalErr[0]PerSample = 0.87500000; TotalTime = 0.1344s; SamplesPerSecond = 1428.8
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: SamplesSeen = 192; TrainLossPerSample =  3.98665980; EvalErr[0]PerSample = 0.89062500; TotalTime = 0.1377s; SamplesPerSecond = 1394.8
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: SamplesSeen = 192; TrainLossPerSample =  4.04770240; EvalErr[0]PerSample = 0.86979167; TotalTime = 0.1347s; SamplesPerSecond = 1425.2
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: SamplesSeen = 192; TrainLossPerSample =  3.90302828; EvalErr[0]PerSample = 0.82812500; TotalTime = 0.1302s; SamplesPerSecond = 1474.9
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: SamplesSeen = 192; TrainLossPerSample =  3.86543260; EvalErr[0]PerSample = 0.85416667; TotalTime = 0.1333s; SamplesPerSecond = 1440.7
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: SamplesSeen = 192; TrainLossPerSample =  3.91647287; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1326s; SamplesPerSecond = 1448.3
MPI Rank 0: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: SamplesSeen = 192; TrainLossPerSample =  4.12386071; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1318s; SamplesPerSecond = 1456.7
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: SamplesSeen = 192; TrainLossPerSample =  3.69087731; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1309s; SamplesPerSecond = 1466.7
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.13%]: SamplesSeen = 192; TrainLossPerSample =  3.88162836; EvalErr[0]PerSample = 0.90104167; TotalTime = 0.1285s; SamplesPerSecond = 1493.7
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: SamplesSeen = 192; TrainLossPerSample =  3.87472683; EvalErr[0]PerSample = 0.88541667; TotalTime = 0.1297s; SamplesPerSecond = 1479.9
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: SamplesSeen = 192; TrainLossPerSample =  3.86120572; EvalErr[0]PerSample = 0.91145833; TotalTime = 0.1354s; SamplesPerSecond = 1418.4
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: SamplesSeen = 192; TrainLossPerSample =  3.78233163; EvalErr[0]PerSample = 0.95833333; TotalTime = 0.1278s; SamplesPerSecond = 1501.9
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: SamplesSeen = 192; TrainLossPerSample =  3.62749940; EvalErr[0]PerSample = 0.85937500; TotalTime = 0.1318s; SamplesPerSecond = 1456.2
MPI Rank 0: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: SamplesSeen = 192; TrainLossPerSample =  3.66544034; EvalErr[0]PerSample = 0.85937500; TotalTime = 0.1289s; SamplesPerSecond = 1489.1
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: SamplesSeen = 192; TrainLossPerSample =  3.79012623; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1330s; SamplesPerSecond = 1443.8
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: SamplesSeen = 192; TrainLossPerSample =  3.43838716; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1168s; SamplesPerSecond = 1643.6
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.63%]: SamplesSeen = 192; TrainLossPerSample =  3.48802836; EvalErr[0]PerSample = 0.80208333; TotalTime = 0.1430s; SamplesPerSecond = 1342.9
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: SamplesSeen = 192; TrainLossPerSample =  3.52297384; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1343s; SamplesPerSecond = 1429.8
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: SamplesSeen = 192; TrainLossPerSample =  3.56777881; EvalErr[0]PerSample = 0.79687500; TotalTime = 0.1287s; SamplesPerSecond = 1491.3
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: SamplesSeen = 192; TrainLossPerSample =  3.60709825; EvalErr[0]PerSample = 0.86979167; TotalTime = 0.1326s; SamplesPerSecond = 1448.5
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: SamplesSeen = 192; TrainLossPerSample =  3.43851505; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1289s; SamplesPerSecond = 1489.0
MPI Rank 0: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: SamplesSeen = 192; TrainLossPerSample =  3.43456895; EvalErr[0]PerSample = 0.79687500; TotalTime = 0.1302s; SamplesPerSecond = 1475.1
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: SamplesSeen = 192; TrainLossPerSample =  3.34869877; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1304s; SamplesPerSecond = 1472.9
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: SamplesSeen = 192; TrainLossPerSample =  3.36772827; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1325s; SamplesPerSecond = 1449.4
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.13%]: SamplesSeen = 192; TrainLossPerSample =  3.20391887; EvalErr[0]PerSample = 0.75520833; TotalTime = 0.1308s; SamplesPerSecond = 1467.6
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: SamplesSeen = 192; TrainLossPerSample =  3.47766749; EvalErr[0]PerSample = 0.78645833; TotalTime = 0.1301s; SamplesPerSecond = 1475.7
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: SamplesSeen = 192; TrainLossPerSample =  3.44215927; EvalErr[0]PerSample = 0.78645833; TotalTime = 0.1326s; SamplesPerSecond = 1448.1
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: SamplesSeen = 192; TrainLossPerSample =  3.55408161; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1288s; SamplesPerSecond = 1490.2
MPI Rank 0: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: SamplesSeen = 192; TrainLossPerSample =  3.50092522; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1299s; SamplesPerSecond = 1478.2
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: SamplesSeen = 192; TrainLossPerSample =  3.41013285; EvalErr[0]PerSample = 0.84895833; TotalTime = 0.1230s; SamplesPerSecond = 1561.4
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: SamplesSeen = 192; TrainLossPerSample =  2.90759530; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1427s; SamplesPerSecond = 1345.1
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: SamplesSeen = 192; TrainLossPerSample =  3.22389482; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1308s; SamplesPerSecond = 1468.3
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.63%]: SamplesSeen = 192; TrainLossPerSample =  3.30804350; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1359s; SamplesPerSecond = 1413.0
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: SamplesSeen = 192; TrainLossPerSample =  3.25288116; EvalErr[0]PerSample = 0.81250000; TotalTime = 0.1338s; SamplesPerSecond = 1434.5
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: SamplesSeen = 192; TrainLossPerSample =  3.35903793; EvalErr[0]PerSample = 0.79166667; TotalTime = 0.1277s; SamplesPerSecond = 1503.1
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: SamplesSeen = 192; TrainLossPerSample =  3.30650873; EvalErr[0]PerSample = 0.81250000; TotalTime = 0.1306s; SamplesPerSecond = 1470.3
MPI Rank 0: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: SamplesSeen = 192; TrainLossPerSample =  3.06345980; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1306s; SamplesPerSecond = 1470.6
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: SamplesSeen = 192; TrainLossPerSample =  3.15381499; EvalErr[0]PerSample = 0.74479167; TotalTime = 0.1308s; SamplesPerSecond = 1467.4
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: SamplesSeen = 192; TrainLossPerSample =  2.99509528; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1367s; SamplesPerSecond = 1404.5
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: SamplesSeen = 192; TrainLossPerSample =  3.18449473; EvalErr[0]PerSample = 0.81770833; TotalTime = 0.1304s; SamplesPerSecond = 1472.4
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.13%]: SamplesSeen = 192; TrainLossPerSample =  3.08900703; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1187s; SamplesPerSecond = 1617.5
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: SamplesSeen = 192; TrainLossPerSample =  2.96007948; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1438s; SamplesPerSecond = 1334.8
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: SamplesSeen = 192; TrainLossPerSample =  3.17646703; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1309s; SamplesPerSecond = 1466.8
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: SamplesSeen = 192; TrainLossPerSample =  3.04459700; EvalErr[0]PerSample = 0.72395833; TotalTime = 0.1308s; SamplesPerSecond = 1468.1
MPI Rank 0: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: SamplesSeen = 192; TrainLossPerSample =  3.00481869; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1307s; SamplesPerSecond = 1469.5
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: SamplesSeen = 192; TrainLossPerSample =  2.88356763; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1309s; SamplesPerSecond = 1466.8
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: SamplesSeen = 192; TrainLossPerSample =  3.05230853; EvalErr[0]PerSample = 0.73958333; TotalTime = 0.1344s; SamplesPerSecond = 1429.0
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: SamplesSeen = 192; TrainLossPerSample =  2.81339450; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1273s; SamplesPerSecond = 1508.4
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.63%]: SamplesSeen = 192; TrainLossPerSample =  2.96349055; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1444s; SamplesPerSecond = 1329.6
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: SamplesSeen = 192; TrainLossPerSample =  2.79795016; EvalErr[0]PerSample = 0.67708333; TotalTime = 0.1341s; SamplesPerSecond = 1431.4
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: SamplesSeen = 192; TrainLossPerSample =  2.97208651; EvalErr[0]PerSample = 0.76562500; TotalTime = 0.1315s; SamplesPerSecond = 1460.2
MPI Rank 0: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: SamplesSeen = 192; TrainLossPerSample =  2.82155741; EvalErr[0]PerSample = 0.70833333; TotalTime = 0.1217s; SamplesPerSecond = 1577.9
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: SamplesSeen = 192; TrainLossPerSample =  2.63811824; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1384s; SamplesPerSecond = 1386.9
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: SamplesSeen = 192; TrainLossPerSample =  2.77075492; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1294s; SamplesPerSecond = 1483.5
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: SamplesSeen = 192; TrainLossPerSample =  2.74441211; EvalErr[0]PerSample = 0.70312500; TotalTime = 0.1362s; SamplesPerSecond = 1409.8
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: SamplesSeen = 192; TrainLossPerSample =  2.63317367; EvalErr[0]PerSample = 0.69791667; TotalTime = 0.1459s; SamplesPerSecond = 1316.0
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: SamplesSeen = 192; TrainLossPerSample =  2.84529497; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1301s; SamplesPerSecond = 1476.0
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: SamplesSeen = 192; TrainLossPerSample =  2.61228778; EvalErr[0]PerSample = 0.64583333; TotalTime = 0.1313s; SamplesPerSecond = 1462.8
MPI Rank 0: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: SamplesSeen = 192; TrainLossPerSample =  2.57824925; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1341s; SamplesPerSecond = 1432.1
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: SamplesSeen = 192; TrainLossPerSample =  2.71402776; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1285s; SamplesPerSecond = 1494.3
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: SamplesSeen = 192; TrainLossPerSample =  2.64823732; EvalErr[0]PerSample = 0.67708333; TotalTime = 0.1326s; SamplesPerSecond = 1448.0
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: SamplesSeen = 192; TrainLossPerSample =  2.69907749; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1361s; SamplesPerSecond = 1410.8
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: SamplesSeen = 192; TrainLossPerSample =  2.56462326; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1305s; SamplesPerSecond = 1471.7
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: SamplesSeen = 192; TrainLossPerSample =  2.51752425; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1322s; SamplesPerSecond = 1452.5
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.63%]: SamplesSeen = 192; TrainLossPerSample =  2.39838052; EvalErr[0]PerSample = 0.66666667; TotalTime = 0.1233s; SamplesPerSecond = 1557.1
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: SamplesSeen = 192; TrainLossPerSample =  2.67807980; EvalErr[0]PerSample = 0.71875000; TotalTime = 0.1384s; SamplesPerSecond = 1387.6
MPI Rank 0: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: SamplesSeen = 192; TrainLossPerSample =  2.71483202; EvalErr[0]PerSample = 0.68229167; TotalTime = 0.1304s; SamplesPerSecond = 1472.7
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: SamplesSeen = 192; TrainLossPerSample =  2.51324154; EvalErr[0]PerSample = 0.62500000; TotalTime = 0.1272s; SamplesPerSecond = 1509.7
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: SamplesSeen = 192; TrainLossPerSample =  2.50649730; EvalErr[0]PerSample = 0.68750000; TotalTime = 0.1505s; SamplesPerSecond = 1275.8
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: SamplesSeen = 192; TrainLossPerSample =  2.67678541; EvalErr[0]PerSample = 0.70312500; TotalTime = 0.1310s; SamplesPerSecond = 1465.1
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: SamplesSeen = 192; TrainLossPerSample =  2.37840607; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1297s; SamplesPerSecond = 1480.0
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: SamplesSeen = 192; TrainLossPerSample =  2.43624298; EvalErr[0]PerSample = 0.67187500; TotalTime = 0.1312s; SamplesPerSecond = 1463.5
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.13%]: SamplesSeen = 192; TrainLossPerSample =  2.43409065; EvalErr[0]PerSample = 0.61979167; TotalTime = 0.1296s; SamplesPerSecond = 1481.2
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: SamplesSeen = 192; TrainLossPerSample =  2.52589262; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1321s; SamplesPerSecond = 1454.0
MPI Rank 0: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: SamplesSeen = 192; TrainLossPerSample =  2.49519410; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1287s; SamplesPerSecond = 1491.4
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: SamplesSeen = 192; TrainLossPerSample =  2.43278558; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1298s; SamplesPerSecond = 1479.4
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: SamplesSeen = 192; TrainLossPerSample =  2.40515550; EvalErr[0]PerSample = 0.60416667; TotalTime = 0.1330s; SamplesPerSecond = 1443.6
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: SamplesSeen = 192; TrainLossPerSample =  2.57558579; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1219s; SamplesPerSecond = 1575.6
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: SamplesSeen = 192; TrainLossPerSample =  2.23121798; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1379s; SamplesPerSecond = 1392.5
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: SamplesSeen = 192; TrainLossPerSample =  2.50920913; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1325s; SamplesPerSecond = 1448.7
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.63%]: SamplesSeen = 192; TrainLossPerSample =  2.51602794; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1300s; SamplesPerSecond = 1476.9
MPI Rank 0: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: SamplesSeen = 192; TrainLossPerSample =  2.19041609; EvalErr[0]PerSample = 0.56250000; TotalTime = 0.1305s; SamplesPerSecond = 1471.3
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: SamplesSeen = 192; TrainLossPerSample =  2.14558034; EvalErr[0]PerSample = 0.52083333; TotalTime = 0.1309s; SamplesPerSecond = 1466.6
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: SamplesSeen = 192; TrainLossPerSample =  2.26397052; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1314s; SamplesPerSecond = 1461.1
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: SamplesSeen = 192; TrainLossPerSample =  2.13992092; EvalErr[0]PerSample = 0.62500000; TotalTime = 0.1336s; SamplesPerSecond = 1436.8
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: SamplesSeen = 192; TrainLossPerSample =  2.46059836; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1273s; SamplesPerSecond = 1507.7
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: SamplesSeen = 192; TrainLossPerSample =  2.11174554; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1294s; SamplesPerSecond = 1483.7
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: SamplesSeen = 192; TrainLossPerSample =  2.36329481; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1299s; SamplesPerSecond = 1477.6
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.13%]: SamplesSeen = 192; TrainLossPerSample =  2.33020684; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1313s; SamplesPerSecond = 1462.3
MPI Rank 0: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: SamplesSeen = 192; TrainLossPerSample =  2.24993200; EvalErr[0]PerSample = 0.59375000; TotalTime = 0.1294s; SamplesPerSecond = 1483.7
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: SamplesSeen = 192; TrainLossPerSample =  2.21490528; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1307s; SamplesPerSecond = 1468.6
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: SamplesSeen = 192; TrainLossPerSample =  2.18525455; EvalErr[0]PerSample = 0.56770833; TotalTime = 0.1301s; SamplesPerSecond = 1475.6
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: SamplesSeen = 192; TrainLossPerSample =  2.37028991; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1347s; SamplesPerSecond = 1425.7
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: SamplesSeen = 192; TrainLossPerSample =  2.02858610; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1294s; SamplesPerSecond = 1483.3
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: SamplesSeen = 192; TrainLossPerSample =  2.12060224; EvalErr[0]PerSample = 0.58854167; TotalTime = 0.1308s; SamplesPerSecond = 1467.6
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: SamplesSeen = 192; TrainLossPerSample =  2.24345126; EvalErr[0]PerSample = 0.54166667; TotalTime = 0.1306s; SamplesPerSecond = 1470.5
MPI Rank 0: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.63%]: SamplesSeen = 192; TrainLossPerSample =  2.23414476; EvalErr[0]PerSample = 0.58854167; TotalTime = 0.1304s; SamplesPerSecond = 1472.5
MPI Rank 0: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: SamplesSeen = 192; TrainLossPerSample =  2.24515288; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1298s; SamplesPerSecond = 1478.7
MPI Rank 0: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: SamplesSeen = 192; TrainLossPerSample =  2.14391664; EvalErr[0]PerSample = 0.64583333; TotalTime = 0.1312s; SamplesPerSecond = 1463.9
MPI Rank 0: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: SamplesSeen = 192; TrainLossPerSample =  2.31221990; EvalErr[0]PerSample = 0.63541667; TotalTime = 0.1497s; SamplesPerSecond = 1282.5
MPI Rank 0: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: SamplesSeen = 192; TrainLossPerSample =  2.34285218; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1482s; SamplesPerSecond = 1295.1
MPI Rank 0: 04/28/2016 15:42:45: Finished Epoch[ 1 of 5]: [Training Set] TrainLossPerSample = 3.000912; TotalSamplesSeen = 20480; EvalErrPerSample = 0.72744141; AvgLearningRatePerSample = 0.015625; EpochTime=14.1499
MPI Rank 0: 04/28/2016 15:42:45: SGD: Saving checkpoint model 'C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:45: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: SamplesSeen = 476; TrainLossPerSample =  2.09385973; EvalErr[0]PerSample = 0.55672269; TotalTime = 0.3037s; SamplesPerSecond = 1567.6
MPI Rank 0: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: SamplesSeen = 520; TrainLossPerSample =  2.13863313; EvalErr[0]PerSample = 0.57115385; TotalTime = 0.2467s; SamplesPerSecond = 2107.8
MPI Rank 0: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: SamplesSeen = 492; TrainLossPerSample =  2.15664770; EvalErr[0]PerSample = 0.57520325; TotalTime = 0.2104s; SamplesPerSecond = 2338.0
MPI Rank 0: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: SamplesSeen = 518; TrainLossPerSample =  2.13749835; EvalErr[0]PerSample = 0.56177606; TotalTime = 0.2169s; SamplesPerSecond = 2388.3
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.35 seconds since last report (0.00 seconds on comm.); -842146208 samples processed by 2 workers (-842148265 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 10960017805017088.00k samplesPerSecond , throughputPerWorker = 5480008902508544.00k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: SamplesSeen = 520; TrainLossPerSample =  2.09914722; EvalErr[0]PerSample = 0.57115385; TotalTime = 0.5152s; SamplesPerSecond = 1009.3
MPI Rank 0: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: SamplesSeen = 474; TrainLossPerSample =  1.93242824; EvalErr[0]PerSample = 0.53375527; TotalTime = 0.2395s; SamplesPerSecond = 1979.2
MPI Rank 0: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: SamplesSeen = 510; TrainLossPerSample =  1.93722183; EvalErr[0]PerSample = 0.49607843; TotalTime = 0.2336s; SamplesPerSecond = 2183.5
MPI Rank 0: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: SamplesSeen = 489; TrainLossPerSample =  2.00288951; EvalErr[0]PerSample = 0.56850716; TotalTime = 0.2084s; SamplesPerSecond = 2346.5
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.36 seconds since last report (0.00 seconds on comm.); 4292 samples processed by 2 workers (2153 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 3.15k samplesPerSecond , throughputPerWorker = 1.58k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: SamplesSeen = 501; TrainLossPerSample =  2.00513839; EvalErr[0]PerSample = 0.53692615; TotalTime = 0.5924s; SamplesPerSecond = 845.7
MPI Rank 0: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: SamplesSeen = 490; TrainLossPerSample =  2.09047161; EvalErr[0]PerSample = 0.57959184; TotalTime = 0.2323s; SamplesPerSecond = 2109.7
MPI Rank 0: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: SamplesSeen = 515; TrainLossPerSample =  1.83811727; EvalErr[0]PerSample = 0.49902913; TotalTime = 0.2167s; SamplesPerSecond = 2376.1
MPI Rank 0: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: SamplesSeen = 482; TrainLossPerSample =  1.99549155; EvalErr[0]PerSample = 0.56016598; TotalTime = 0.2196s; SamplesPerSecond = 2194.7
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.36 seconds since last report (0.00 seconds on comm.); 4263 samples processed by 2 workers (2126 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 3.14k samplesPerSecond , throughputPerWorker = 1.57k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: SamplesSeen = 478; TrainLossPerSample =  1.90986165; EvalErr[0]PerSample = 0.51255230; TotalTime = 0.6096s; SamplesPerSecond = 784.1
MPI Rank 0: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: SamplesSeen = 471; TrainLossPerSample =  1.81353535; EvalErr[0]PerSample = 0.53078556; TotalTime = 0.2138s; SamplesPerSecond = 2202.8
MPI Rank 0: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: SamplesSeen = 480; TrainLossPerSample =  1.86106692; EvalErr[0]PerSample = 0.49166667; TotalTime = 0.2160s; SamplesPerSecond = 2222.1
MPI Rank 0: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: SamplesSeen = 487; TrainLossPerSample =  1.86198572; EvalErr[0]PerSample = 0.48049281; TotalTime = 0.2190s; SamplesPerSecond = 2224.0
MPI Rank 0: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: SamplesSeen = 476; TrainLossPerSample =  1.98663146; EvalErr[0]PerSample = 0.51890756; TotalTime = 0.2075s; SamplesPerSecond = 2293.6
MPI Rank 0: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: SamplesSeen = 476; TrainLossPerSample =  1.83857284; EvalErr[0]PerSample = 0.52521008; TotalTime = 0.1864s; SamplesPerSecond = 2553.3
MPI Rank 0: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: SamplesSeen = 500; TrainLossPerSample =  1.89980302; EvalErr[0]PerSample = 0.52800000; TotalTime = 0.1743s; SamplesPerSecond = 2868.5
MPI Rank 0: 04/28/2016 15:42:51:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: SamplesSeen = 498; TrainLossPerSample =  1.95483734; EvalErr[0]PerSample = 0.53815261; TotalTime = 0.1700s; SamplesPerSecond = 2929.7
MPI Rank 0: 04/28/2016 15:42:51:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: SamplesSeen = 481; TrainLossPerSample =  1.88908297; EvalErr[0]PerSample = 0.52390852; TotalTime = 0.1784s; SamplesPerSecond = 2696.2
MPI Rank 0: 04/28/2016 15:42:51:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: SamplesSeen = 496; TrainLossPerSample =  1.84475883; EvalErr[0]PerSample = 0.52419355; TotalTime = 0.1679s; SamplesPerSecond = 2954.4
MPI Rank 0: 04/28/2016 15:42:51:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: SamplesSeen = 501; TrainLossPerSample =  1.85382596; EvalErr[0]PerSample = 0.52894212; TotalTime = 0.1701s; SamplesPerSecond = 2946.2
MPI Rank 0: 04/28/2016 15:42:51:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: SamplesSeen = 488; TrainLossPerSample =  1.90982316; EvalErr[0]PerSample = 0.54918033; TotalTime = 0.1689s; SamplesPerSecond = 2889.5
MPI Rank 0: 04/28/2016 15:42:52:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: SamplesSeen = 490; TrainLossPerSample =  1.97109646; EvalErr[0]PerSample = 0.54489796; TotalTime = 0.1718s; SamplesPerSecond = 2851.8
MPI Rank 0: 04/28/2016 15:42:52:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: SamplesSeen = 480; TrainLossPerSample =  1.73504303; EvalErr[0]PerSample = 0.48541667; TotalTime = 0.1682s; SamplesPerSecond = 2853.1
MPI Rank 0: 04/28/2016 15:42:52:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: SamplesSeen = 338; TrainLossPerSample =  1.87620614; EvalErr[0]PerSample = 0.52662722; TotalTime = 0.1006s; SamplesPerSecond = 3358.9
MPI Rank 0: 		(model aggregation stats) 4-th sync:     2.54 seconds since last report (0.00 seconds on comm.); 7682 samples processed by 2 workers (6662 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 3.02k samplesPerSecond , throughputPerWorker = 1.51k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:52: Finished Epoch[ 2 of 5]: [Training Set] TrainLossPerSample = 1.973157; TotalSamplesSeen = 40960; EvalErrPerSample = 0.54174805; AvgLearningRatePerSample = 0.001953125; EpochTime=6.61701
MPI Rank 0: 04/28/2016 15:42:52: SGD: Saving checkpoint model 'C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:52: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/28/2016 15:42:53:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1935; TrainLossPerSample =  1.91765212; EvalErr[0]PerSample = 0.53126615; TotalTime = 0.6849s; SamplesPerSecond = 2825.2
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.21 seconds since last report (0.00 seconds on comm.); 4848 samples processed by 2 workers (2601 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 3.99k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:54:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1962; TrainLossPerSample =  1.84887142; EvalErr[0]PerSample = 0.53109072; TotalTime = 0.9261s; SamplesPerSecond = 2118.5
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.15 seconds since last report (0.00 seconds on comm.); 4857 samples processed by 2 workers (2603 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.10k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:55:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1967; TrainLossPerSample =  1.88081721; EvalErr[0]PerSample = 0.53380783; TotalTime = 0.9324s; SamplesPerSecond = 2109.6
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.16 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2583 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:56:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1923; TrainLossPerSample =  1.80500001; EvalErr[0]PerSample = 0.50338014; TotalTime = 0.9256s; SamplesPerSecond = 2077.5
MPI Rank 0: 04/28/2016 15:42:56:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1914; TrainLossPerSample =  1.95334199; EvalErr[0]PerSample = 0.53291536; TotalTime = 0.5881s; SamplesPerSecond = 3254.6
MPI Rank 0: 04/28/2016 15:42:57:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1908; TrainLossPerSample =  1.93325621; EvalErr[0]PerSample = 0.53511530; TotalTime = 0.5202s; SamplesPerSecond = 3668.2
MPI Rank 0: 04/28/2016 15:42:57:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 1283; TrainLossPerSample =  1.86472404; EvalErr[0]PerSample = 0.51597818; TotalTime = 0.2895s; SamplesPerSecond = 4431.4
MPI Rank 0: 		(model aggregation stats) 4-th sync:     1.42 seconds since last report (0.00 seconds on comm.); 5870 samples processed by 2 workers (5105 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 4.13k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:57: Finished Epoch[ 3 of 5]: [Training Set] TrainLossPerSample = 1.8928518; TotalSamplesSeen = 61440; EvalErrPerSample = 0.52680664; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=4.95496
MPI Rank 0: 04/28/2016 15:42:57: SGD: Saving checkpoint model 'C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:57: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:42:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/28/2016 15:42:58:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1935; TrainLossPerSample =  1.86333327; EvalErr[0]PerSample = 0.50645995; TotalTime = 0.8647s; SamplesPerSecond = 2237.9
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4851 samples processed by 2 workers (2561 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 4.15k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 0: 04/28/2016 15:42:59:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1919; TrainLossPerSample =  1.84529556; EvalErr[0]PerSample = 0.51797811; TotalTime = 0.7196s; SamplesPerSecond = 2666.9
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.18 seconds since last report (0.00 seconds on comm.); 4948 samples processed by 2 workers (2547 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 4.18k samplesPerSecond , throughputPerWorker = 2.09k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:00:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1900; TrainLossPerSample =  1.82866780; EvalErr[0]PerSample = 0.51157895; TotalTime = 0.9448s; SamplesPerSecond = 2011.0
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4911 samples processed by 2 workers (2489 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:01:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1843; TrainLossPerSample =  1.81705569; EvalErr[0]PerSample = 0.50406945; TotalTime = 0.9280s; SamplesPerSecond = 1986.1
MPI Rank 0: 04/28/2016 15:43:01:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1876; TrainLossPerSample =  1.79874941; EvalErr[0]PerSample = 0.49680171; TotalTime = 0.5718s; SamplesPerSecond = 3281.0
MPI Rank 0: 04/28/2016 15:43:02:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1846; TrainLossPerSample =  1.81182023; EvalErr[0]PerSample = 0.50162514; TotalTime = 0.5163s; SamplesPerSecond = 3575.6
MPI Rank 0: 04/28/2016 15:43:02:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 1326; TrainLossPerSample =  1.86284542; EvalErr[0]PerSample = 0.51960784; TotalTime = 0.3314s; SamplesPerSecond = 4001.3
MPI Rank 0: 		(model aggregation stats) 4-th sync:     1.44 seconds since last report (0.00 seconds on comm.); 5770 samples processed by 2 workers (5048 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 4.00k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:02: Finished Epoch[ 4 of 5]: [Training Set] TrainLossPerSample = 1.8321188; TotalSamplesSeen = 81920; EvalErrPerSample = 0.50991211; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=4.96403
MPI Rank 0: 04/28/2016 15:43:02: SGD: Saving checkpoint model 'C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn.4'
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:43:03: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 0: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:43:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/28/2016 15:43:03:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1872; TrainLossPerSample =  1.79614915; EvalErr[0]PerSample = 0.48557692; TotalTime = 0.7234s; SamplesPerSecond = 2587.9
MPI Rank 0: 		(model aggregation stats) 1-th sync:     1.30 seconds since last report (0.00 seconds on comm.); 4879 samples processed by 2 workers (2475 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 3.76k samplesPerSecond , throughputPerWorker = 1.88k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:04:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1868; TrainLossPerSample =  1.80463920; EvalErr[0]PerSample = 0.49197002; TotalTime = 0.9882s; SamplesPerSecond = 1890.4
MPI Rank 0: 		(model aggregation stats) 2-th sync:     1.14 seconds since last report (0.00 seconds on comm.); 4542 samples processed by 2 workers (2483 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 3.97k samplesPerSecond , throughputPerWorker = 1.99k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1839; TrainLossPerSample =  1.72412279; EvalErr[0]PerSample = 0.46601414; TotalTime = 0.9287s; SamplesPerSecond = 1980.1
MPI Rank 0: 		(model aggregation stats) 3-th sync:     1.21 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2461 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 4.05k samplesPerSecond , throughputPerWorker = 2.02k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:06:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1840; TrainLossPerSample =  1.83556224; EvalErr[0]PerSample = 0.49565217; TotalTime = 0.9445s; SamplesPerSecond = 1948.2
MPI Rank 0: 04/28/2016 15:43:07:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1846; TrainLossPerSample =  1.81120380; EvalErr[0]PerSample = 0.50650054; TotalTime = 0.6609s; SamplesPerSecond = 2793.2
MPI Rank 0: 04/28/2016 15:43:07:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1858; TrainLossPerSample =  1.82333172; EvalErr[0]PerSample = 0.50215285; TotalTime = 0.5573s; SamplesPerSecond = 3333.7
MPI Rank 0: 04/28/2016 15:43:08:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 1296; TrainLossPerSample =  1.79813355; EvalErr[0]PerSample = 0.50540123; TotalTime = 0.2956s; SamplesPerSecond = 4384.6
MPI Rank 0: 		(model aggregation stats) 4-th sync:     1.54 seconds since last report (0.00 seconds on comm.); 6154 samples processed by 2 workers (5000 by me);
MPI Rank 0: 		(model aggregation stats) 4-th sync: totalThroughput = 4.01k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 0: 04/28/2016 15:43:08: Finished Epoch[ 5 of 5]: [Training Set] TrainLossPerSample = 1.7933205; TotalSamplesSeen = 102400; EvalErrPerSample = 0.49741211; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=5.19123
MPI Rank 0: 04/28/2016 15:43:08: SGD: Saving checkpoint model 'C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn'
MPI Rank 0: 04/28/2016 15:43:08: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:43:08: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 04/28/2016 15:43:08: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 04/28/2016 15:41:56: Redirecting stderr to file C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr_speechTrain.logrank1
MPI Rank 1: 04/28/2016 15:41:56: -------------------------------------------------------------------
MPI Rank 1: 04/28/2016 15:41:56: Build info: 
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: 		Built time: Apr 28 2016 15:12:06
MPI Rank 1: 04/28/2016 15:41:56: 		Last modified date: Mon Apr 11 11:57:54 2016
MPI Rank 1: 04/28/2016 15:41:56: 		Build type: Debug
MPI Rank 1: 04/28/2016 15:41:56: 		Build target: GPU
MPI Rank 1: 04/28/2016 15:41:56: 		With 1bit-SGD: yes
MPI Rank 1: 04/28/2016 15:41:56: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
MPI Rank 1: 04/28/2016 15:41:56: 		CUB_PATH: D:\work\Program\Code\src\CUB
MPI Rank 1: 04/28/2016 15:41:56: 		CUDNN_PATH: D:\work\Program\Code\src\cuDNN\cuda
MPI Rank 1: 04/28/2016 15:41:56: 		Build Branch: erw/bm_rc
MPI Rank 1: 04/28/2016 15:41:56: 		Build SHA1: e316467a84d39f17603f4799a8458e8b5eb28a85 (modified)
MPI Rank 1: 04/28/2016 15:41:56: 		Built by erw on 7253-Wang
MPI Rank 1: 04/28/2016 15:41:56: 		Build Path: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Source\CNTK\
MPI Rank 1: 04/28/2016 15:41:56: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: Running on 7253-Wang at 2016/04/28 15:41:56
MPI Rank 1: 04/28/2016 15:41:56: Command line: 
MPI Rank 1: D:\work\Program\Code\local-src\CNTK-public\CNTK-github\x64\debug\cntk.exe  configFile=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk  currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu  DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data  ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu  DeviceId=0  timestamping=true  numCPUThreads=4  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/28/2016 15:41:56: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 syncPeriod=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=4
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/28/2016 15:41:56: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = 0
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 syncPeriod=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=4
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=0
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=4
MPI Rank 1: configparameters: cntk.cntk:OutputDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 syncPeriod=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 04/28/2016 15:41:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 04/28/2016 15:41:56: Commands: speechTrain
MPI Rank 1: 04/28/2016 15:41:56: Precision = "double"
MPI Rank 1: 04/28/2016 15:41:56: Using 4 CPU threads.
MPI Rank 1: 04/28/2016 15:41:56: CNTKModelPath: C:\Users\erw\AppData\Local\Temp\cntk-test-20160428153804.799990\Speech\DNN_ParallelBM@debug_gpu/models/cntkSpeech.dnn
MPI Rank 1: 04/28/2016 15:41:56: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 04/28/2016 15:41:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: ##############################################################################
MPI Rank 1: 04/28/2016 15:41:56: #                                                                            #
MPI Rank 1: 04/28/2016 15:41:56: # Action "train"                                                             #
MPI Rank 1: 04/28/2016 15:41:56: #                                                                            #
MPI Rank 1: 04/28/2016 15:41:56: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:56: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 948 entries
MPI Rank 1: total 132 state names in state list D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file D:\work\Program\Code\local-src\CNTK-public\CNTK-github\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:58: Creating virgin network.
MPI Rank 1: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: Created model with 25 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: Training criterion node(s):
MPI Rank 1: 04/28/2016 15:41:59: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:41:59: 	MeanOfFeatures = Mean()
MPI Rank 1: 04/28/2016 15:41:59: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 04/28/2016 15:41:59: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252734] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:31: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:31: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:31: Starting minibatch loop.
MPI Rank 1: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: SamplesSeen = 192; TrainLossPerSample =  4.59555827; EvalErr[0]PerSample = 0.95312500; TotalTime = 0.1556s; SamplesPerSecond = 1233.8
MPI Rank 1: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: SamplesSeen = 192; TrainLossPerSample =  4.63574590; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1424s; SamplesPerSecond = 1348.2
MPI Rank 1: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: SamplesSeen = 192; TrainLossPerSample =  4.40475736; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1332s; SamplesPerSecond = 1441.6
MPI Rank 1: 04/28/2016 15:42:31:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: SamplesSeen = 192; TrainLossPerSample =  4.37017519; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1324s; SamplesPerSecond = 1450.1
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: SamplesSeen = 192; TrainLossPerSample =  4.34202026; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1300s; SamplesPerSecond = 1477.0
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.63%]: SamplesSeen = 192; TrainLossPerSample =  4.05288419; EvalErr[0]PerSample = 0.87500000; TotalTime = 0.1297s; SamplesPerSecond = 1480.8
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: SamplesSeen = 192; TrainLossPerSample =  3.98665980; EvalErr[0]PerSample = 0.89062500; TotalTime = 0.1288s; SamplesPerSecond = 1490.7
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: SamplesSeen = 192; TrainLossPerSample =  4.04770240; EvalErr[0]PerSample = 0.86979167; TotalTime = 0.1184s; SamplesPerSecond = 1621.3
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: SamplesSeen = 192; TrainLossPerSample =  3.90302828; EvalErr[0]PerSample = 0.82812500; TotalTime = 0.1463s; SamplesPerSecond = 1312.7
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: SamplesSeen = 192; TrainLossPerSample =  3.86543260; EvalErr[0]PerSample = 0.85416667; TotalTime = 0.1310s; SamplesPerSecond = 1465.1
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: SamplesSeen = 192; TrainLossPerSample =  3.91647287; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1206s; SamplesPerSecond = 1591.7
MPI Rank 1: 04/28/2016 15:42:32:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: SamplesSeen = 192; TrainLossPerSample =  4.12386071; EvalErr[0]PerSample = 0.92187500; TotalTime = 0.1316s; SamplesPerSecond = 1459.4
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: SamplesSeen = 192; TrainLossPerSample =  3.69087731; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1432s; SamplesPerSecond = 1340.5
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.13%]: SamplesSeen = 192; TrainLossPerSample =  3.88162836; EvalErr[0]PerSample = 0.90104167; TotalTime = 0.1302s; SamplesPerSecond = 1475.0
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: SamplesSeen = 192; TrainLossPerSample =  3.87472683; EvalErr[0]PerSample = 0.88541667; TotalTime = 0.1302s; SamplesPerSecond = 1474.5
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: SamplesSeen = 192; TrainLossPerSample =  3.86120572; EvalErr[0]PerSample = 0.91145833; TotalTime = 0.1174s; SamplesPerSecond = 1635.5
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: SamplesSeen = 192; TrainLossPerSample =  3.78233163; EvalErr[0]PerSample = 0.95833333; TotalTime = 0.1451s; SamplesPerSecond = 1322.9
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: SamplesSeen = 192; TrainLossPerSample =  3.62749940; EvalErr[0]PerSample = 0.85937500; TotalTime = 0.1185s; SamplesPerSecond = 1620.5
MPI Rank 1: 04/28/2016 15:42:33:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: SamplesSeen = 192; TrainLossPerSample =  3.66544034; EvalErr[0]PerSample = 0.85937500; TotalTime = 0.1431s; SamplesPerSecond = 1342.1
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: SamplesSeen = 192; TrainLossPerSample =  3.79012623; EvalErr[0]PerSample = 0.90625000; TotalTime = 0.1306s; SamplesPerSecond = 1470.3
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: SamplesSeen = 192; TrainLossPerSample =  3.43838716; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1318s; SamplesPerSecond = 1456.7
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.63%]: SamplesSeen = 192; TrainLossPerSample =  3.48802836; EvalErr[0]PerSample = 0.80208333; TotalTime = 0.1297s; SamplesPerSecond = 1479.9
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: SamplesSeen = 192; TrainLossPerSample =  3.52297384; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1183s; SamplesPerSecond = 1623.5
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: SamplesSeen = 192; TrainLossPerSample =  3.56777881; EvalErr[0]PerSample = 0.79687500; TotalTime = 0.1456s; SamplesPerSecond = 1318.7
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: SamplesSeen = 192; TrainLossPerSample =  3.60709825; EvalErr[0]PerSample = 0.86979167; TotalTime = 0.1297s; SamplesPerSecond = 1480.4
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: SamplesSeen = 192; TrainLossPerSample =  3.43851505; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1308s; SamplesPerSecond = 1468.0
MPI Rank 1: 04/28/2016 15:42:34:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: SamplesSeen = 192; TrainLossPerSample =  3.43456895; EvalErr[0]PerSample = 0.79687500; TotalTime = 0.1309s; SamplesPerSecond = 1466.6
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: SamplesSeen = 192; TrainLossPerSample =  3.34869877; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1299s; SamplesPerSecond = 1478.0
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: SamplesSeen = 192; TrainLossPerSample =  3.36772827; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1327s; SamplesPerSecond = 1447.4
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.13%]: SamplesSeen = 192; TrainLossPerSample =  3.20391887; EvalErr[0]PerSample = 0.75520833; TotalTime = 0.1303s; SamplesPerSecond = 1473.3
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: SamplesSeen = 192; TrainLossPerSample =  3.47766749; EvalErr[0]PerSample = 0.78645833; TotalTime = 0.1309s; SamplesPerSecond = 1467.2
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: SamplesSeen = 192; TrainLossPerSample =  3.44215927; EvalErr[0]PerSample = 0.78645833; TotalTime = 0.1304s; SamplesPerSecond = 1472.0
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: SamplesSeen = 192; TrainLossPerSample =  3.55408161; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1185s; SamplesPerSecond = 1620.5
MPI Rank 1: 04/28/2016 15:42:35:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: SamplesSeen = 192; TrainLossPerSample =  3.50092522; EvalErr[0]PerSample = 0.83333333; TotalTime = 0.1425s; SamplesPerSecond = 1347.8
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: SamplesSeen = 192; TrainLossPerSample =  3.41013285; EvalErr[0]PerSample = 0.84895833; TotalTime = 0.1363s; SamplesPerSecond = 1409.1
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: SamplesSeen = 192; TrainLossPerSample =  2.90759530; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1177s; SamplesPerSecond = 1630.7
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: SamplesSeen = 192; TrainLossPerSample =  3.22389482; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1424s; SamplesPerSecond = 1348.5
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.63%]: SamplesSeen = 192; TrainLossPerSample =  3.30804350; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1182s; SamplesPerSecond = 1623.9
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: SamplesSeen = 192; TrainLossPerSample =  3.25288116; EvalErr[0]PerSample = 0.81250000; TotalTime = 0.1367s; SamplesPerSecond = 1404.9
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: SamplesSeen = 192; TrainLossPerSample =  3.35903793; EvalErr[0]PerSample = 0.79166667; TotalTime = 0.1427s; SamplesPerSecond = 1345.9
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: SamplesSeen = 192; TrainLossPerSample =  3.30650873; EvalErr[0]PerSample = 0.81250000; TotalTime = 0.1193s; SamplesPerSecond = 1609.4
MPI Rank 1: 04/28/2016 15:42:36:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: SamplesSeen = 192; TrainLossPerSample =  3.06345980; EvalErr[0]PerSample = 0.77604167; TotalTime = 0.1423s; SamplesPerSecond = 1349.1
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: SamplesSeen = 192; TrainLossPerSample =  3.15381499; EvalErr[0]PerSample = 0.74479167; TotalTime = 0.1307s; SamplesPerSecond = 1469.4
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: SamplesSeen = 192; TrainLossPerSample =  2.99509528; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1347s; SamplesPerSecond = 1425.0
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: SamplesSeen = 192; TrainLossPerSample =  3.18449473; EvalErr[0]PerSample = 0.81770833; TotalTime = 0.1325s; SamplesPerSecond = 1449.0
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.13%]: SamplesSeen = 192; TrainLossPerSample =  3.08900703; EvalErr[0]PerSample = 0.82291667; TotalTime = 0.1332s; SamplesPerSecond = 1441.9
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: SamplesSeen = 192; TrainLossPerSample =  2.96007948; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1302s; SamplesPerSecond = 1474.1
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: SamplesSeen = 192; TrainLossPerSample =  3.17646703; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1302s; SamplesPerSecond = 1474.3
MPI Rank 1: 04/28/2016 15:42:37:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: SamplesSeen = 192; TrainLossPerSample =  3.04459700; EvalErr[0]PerSample = 0.72395833; TotalTime = 0.1232s; SamplesPerSecond = 1557.8
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: SamplesSeen = 192; TrainLossPerSample =  3.00481869; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1390s; SamplesPerSecond = 1380.9
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: SamplesSeen = 192; TrainLossPerSample =  2.88356763; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1301s; SamplesPerSecond = 1476.3
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: SamplesSeen = 192; TrainLossPerSample =  3.05230853; EvalErr[0]PerSample = 0.73958333; TotalTime = 0.1365s; SamplesPerSecond = 1406.9
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: SamplesSeen = 192; TrainLossPerSample =  2.81339450; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1390s; SamplesPerSecond = 1381.2
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.63%]: SamplesSeen = 192; TrainLossPerSample =  2.96349055; EvalErr[0]PerSample = 0.73437500; TotalTime = 0.1319s; SamplesPerSecond = 1455.6
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: SamplesSeen = 192; TrainLossPerSample =  2.79795016; EvalErr[0]PerSample = 0.67708333; TotalTime = 0.1204s; SamplesPerSecond = 1594.1
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: SamplesSeen = 192; TrainLossPerSample =  2.97208651; EvalErr[0]PerSample = 0.76562500; TotalTime = 0.1292s; SamplesPerSecond = 1485.7
MPI Rank 1: 04/28/2016 15:42:38:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: SamplesSeen = 192; TrainLossPerSample =  2.82155741; EvalErr[0]PerSample = 0.70833333; TotalTime = 0.1473s; SamplesPerSecond = 1303.7
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: SamplesSeen = 192; TrainLossPerSample =  2.63811824; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1274s; SamplesPerSecond = 1507.2
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: SamplesSeen = 192; TrainLossPerSample =  2.77075492; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1317s; SamplesPerSecond = 1458.2
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: SamplesSeen = 192; TrainLossPerSample =  2.74441211; EvalErr[0]PerSample = 0.70312500; TotalTime = 0.1230s; SamplesPerSecond = 1561.5
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: SamplesSeen = 192; TrainLossPerSample =  2.63317367; EvalErr[0]PerSample = 0.69791667; TotalTime = 0.1558s; SamplesPerSecond = 1232.5
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: SamplesSeen = 192; TrainLossPerSample =  2.84529497; EvalErr[0]PerSample = 0.76041667; TotalTime = 0.1315s; SamplesPerSecond = 1460.2
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: SamplesSeen = 192; TrainLossPerSample =  2.61228778; EvalErr[0]PerSample = 0.64583333; TotalTime = 0.1328s; SamplesPerSecond = 1445.8
MPI Rank 1: 04/28/2016 15:42:39:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: SamplesSeen = 192; TrainLossPerSample =  2.57824925; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1319s; SamplesPerSecond = 1456.2
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: SamplesSeen = 192; TrainLossPerSample =  2.71402776; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1300s; SamplesPerSecond = 1477.1
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: SamplesSeen = 192; TrainLossPerSample =  2.64823732; EvalErr[0]PerSample = 0.67708333; TotalTime = 0.1191s; SamplesPerSecond = 1612.7
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: SamplesSeen = 192; TrainLossPerSample =  2.69907749; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1300s; SamplesPerSecond = 1477.0
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: SamplesSeen = 192; TrainLossPerSample =  2.56462326; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1464s; SamplesPerSecond = 1311.9
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: SamplesSeen = 192; TrainLossPerSample =  2.51752425; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1194s; SamplesPerSecond = 1607.5
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.63%]: SamplesSeen = 192; TrainLossPerSample =  2.39838052; EvalErr[0]PerSample = 0.66666667; TotalTime = 0.1467s; SamplesPerSecond = 1309.0
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: SamplesSeen = 192; TrainLossPerSample =  2.67807980; EvalErr[0]PerSample = 0.71875000; TotalTime = 0.1309s; SamplesPerSecond = 1467.0
MPI Rank 1: 04/28/2016 15:42:40:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: SamplesSeen = 192; TrainLossPerSample =  2.71483202; EvalErr[0]PerSample = 0.68229167; TotalTime = 0.1333s; SamplesPerSecond = 1440.0
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: SamplesSeen = 192; TrainLossPerSample =  2.51324154; EvalErr[0]PerSample = 0.62500000; TotalTime = 0.1450s; SamplesPerSecond = 1324.5
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: SamplesSeen = 192; TrainLossPerSample =  2.50649730; EvalErr[0]PerSample = 0.68750000; TotalTime = 0.1286s; SamplesPerSecond = 1492.9
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: SamplesSeen = 192; TrainLossPerSample =  2.67678541; EvalErr[0]PerSample = 0.70312500; TotalTime = 0.1310s; SamplesPerSecond = 1466.1
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: SamplesSeen = 192; TrainLossPerSample =  2.37840607; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1305s; SamplesPerSecond = 1471.4
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: SamplesSeen = 192; TrainLossPerSample =  2.43624298; EvalErr[0]PerSample = 0.67187500; TotalTime = 0.1228s; SamplesPerSecond = 1562.9
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.13%]: SamplesSeen = 192; TrainLossPerSample =  2.43409065; EvalErr[0]PerSample = 0.61979167; TotalTime = 0.1374s; SamplesPerSecond = 1397.3
MPI Rank 1: 04/28/2016 15:42:41:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: SamplesSeen = 192; TrainLossPerSample =  2.52589262; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1187s; SamplesPerSecond = 1617.6
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: SamplesSeen = 192; TrainLossPerSample =  2.49519410; EvalErr[0]PerSample = 0.65104167; TotalTime = 0.1347s; SamplesPerSecond = 1425.7
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: SamplesSeen = 192; TrainLossPerSample =  2.43278558; EvalErr[0]PerSample = 0.63020833; TotalTime = 0.1298s; SamplesPerSecond = 1479.6
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: SamplesSeen = 192; TrainLossPerSample =  2.40515550; EvalErr[0]PerSample = 0.60416667; TotalTime = 0.1405s; SamplesPerSecond = 1366.8
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: SamplesSeen = 192; TrainLossPerSample =  2.57558579; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1322s; SamplesPerSecond = 1451.9
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: SamplesSeen = 192; TrainLossPerSample =  2.23121798; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1167s; SamplesPerSecond = 1644.9
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: SamplesSeen = 192; TrainLossPerSample =  2.50920913; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1443s; SamplesPerSecond = 1330.6
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.63%]: SamplesSeen = 192; TrainLossPerSample =  2.51602794; EvalErr[0]PerSample = 0.66145833; TotalTime = 0.1302s; SamplesPerSecond = 1474.1
MPI Rank 1: 04/28/2016 15:42:42:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: SamplesSeen = 192; TrainLossPerSample =  2.19041609; EvalErr[0]PerSample = 0.56250000; TotalTime = 0.1305s; SamplesPerSecond = 1470.9
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: SamplesSeen = 192; TrainLossPerSample =  2.14558034; EvalErr[0]PerSample = 0.52083333; TotalTime = 0.1192s; SamplesPerSecond = 1610.3
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: SamplesSeen = 192; TrainLossPerSample =  2.26397052; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1423s; SamplesPerSecond = 1349.7
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: SamplesSeen = 192; TrainLossPerSample =  2.13992092; EvalErr[0]PerSample = 0.62500000; TotalTime = 0.1181s; SamplesPerSecond = 1625.2
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: SamplesSeen = 192; TrainLossPerSample =  2.46059836; EvalErr[0]PerSample = 0.69270833; TotalTime = 0.1424s; SamplesPerSecond = 1348.5
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: SamplesSeen = 192; TrainLossPerSample =  2.11174554; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1296s; SamplesPerSecond = 1481.0
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: SamplesSeen = 192; TrainLossPerSample =  2.36329481; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1305s; SamplesPerSecond = 1471.7
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.13%]: SamplesSeen = 192; TrainLossPerSample =  2.33020684; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1192s; SamplesPerSecond = 1611.1
MPI Rank 1: 04/28/2016 15:42:43:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: SamplesSeen = 192; TrainLossPerSample =  2.24993200; EvalErr[0]PerSample = 0.59375000; TotalTime = 0.1416s; SamplesPerSecond = 1356.0
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: SamplesSeen = 192; TrainLossPerSample =  2.21490528; EvalErr[0]PerSample = 0.61458333; TotalTime = 0.1309s; SamplesPerSecond = 1467.0
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: SamplesSeen = 192; TrainLossPerSample =  2.18525455; EvalErr[0]PerSample = 0.56770833; TotalTime = 0.1307s; SamplesPerSecond = 1468.7
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: SamplesSeen = 192; TrainLossPerSample =  2.37028991; EvalErr[0]PerSample = 0.59895833; TotalTime = 0.1183s; SamplesPerSecond = 1623.2
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: SamplesSeen = 192; TrainLossPerSample =  2.02858610; EvalErr[0]PerSample = 0.57291667; TotalTime = 0.1331s; SamplesPerSecond = 1442.3
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: SamplesSeen = 192; TrainLossPerSample =  2.12060224; EvalErr[0]PerSample = 0.58854167; TotalTime = 0.1436s; SamplesPerSecond = 1337.1
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: SamplesSeen = 192; TrainLossPerSample =  2.24345126; EvalErr[0]PerSample = 0.54166667; TotalTime = 0.1296s; SamplesPerSecond = 1481.5
MPI Rank 1: 04/28/2016 15:42:44:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.63%]: SamplesSeen = 192; TrainLossPerSample =  2.23414476; EvalErr[0]PerSample = 0.58854167; TotalTime = 0.1311s; SamplesPerSecond = 1464.5
MPI Rank 1: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: SamplesSeen = 192; TrainLossPerSample =  2.24515288; EvalErr[0]PerSample = 0.64062500; TotalTime = 0.1300s; SamplesPerSecond = 1477.3
MPI Rank 1: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: SamplesSeen = 192; TrainLossPerSample =  2.14391664; EvalErr[0]PerSample = 0.64583333; TotalTime = 0.1308s; SamplesPerSecond = 1467.6
MPI Rank 1: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: SamplesSeen = 192; TrainLossPerSample =  2.31221990; EvalErr[0]PerSample = 0.63541667; TotalTime = 0.1498s; SamplesPerSecond = 1281.9
MPI Rank 1: 04/28/2016 15:42:45:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: SamplesSeen = 192; TrainLossPerSample =  2.34285218; EvalErr[0]PerSample = 0.57812500; TotalTime = 0.1478s; SamplesPerSecond = 1299.2
MPI Rank 1: 04/28/2016 15:42:45: Finished Epoch[ 1 of 5]: [Training Set] TrainLossPerSample = 3.000912; TotalSamplesSeen = 20480; EvalErrPerSample = 0.72744141; AvgLearningRatePerSample = 0.015625; EpochTime=14.1596
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:45: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:45: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/28/2016 15:42:45:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: SamplesSeen = 292; TrainLossPerSample =  2.27199892; EvalErr[0]PerSample = 0.60273973; TotalTime = 0.1714s; SamplesPerSecond = 1703.9
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: SamplesSeen = 248; TrainLossPerSample =  2.16144646; EvalErr[0]PerSample = 0.60080645; TotalTime = 0.1941s; SamplesPerSecond = 1277.5
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: SamplesSeen = 276; TrainLossPerSample =  2.21994551; EvalErr[0]PerSample = 0.61956522; TotalTime = 0.1788s; SamplesPerSecond = 1543.7
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: SamplesSeen = 250; TrainLossPerSample =  2.25986679; EvalErr[0]PerSample = 0.62400000; TotalTime = 0.2102s; SamplesPerSecond = 1189.5
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: SamplesSeen = 248; TrainLossPerSample =  2.01515406; EvalErr[0]PerSample = 0.58467742; TotalTime = 0.2171s; SamplesPerSecond = 1142.5
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: SamplesSeen = 294; TrainLossPerSample =  2.09545622; EvalErr[0]PerSample = 0.54081633; TotalTime = 0.1509s; SamplesPerSecond = 1948.2
MPI Rank 1: 04/28/2016 15:42:46:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: SamplesSeen = 258; TrainLossPerSample =  1.89313519; EvalErr[0]PerSample = 0.50775194; TotalTime = 0.1120s; SamplesPerSecond = 2304.4
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.35 seconds since last report (0.00 seconds on comm.); -842146208 samples processed by 2 workers (-842148394 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 10965001040822272.00k samplesPerSecond , throughputPerWorker = 5482500520411136.00k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: SamplesSeen = 279; TrainLossPerSample =  2.13839262; EvalErr[0]PerSample = 0.54838710; TotalTime = 0.1670s; SamplesPerSecond = 1670.3
MPI Rank 1: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: SamplesSeen = 267; TrainLossPerSample =  2.05379081; EvalErr[0]PerSample = 0.56928839; TotalTime = 0.1784s; SamplesPerSecond = 1496.2
MPI Rank 1: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: SamplesSeen = 278; TrainLossPerSample =  1.92078665; EvalErr[0]PerSample = 0.56115108; TotalTime = 0.2316s; SamplesPerSecond = 1200.2
MPI Rank 1: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: SamplesSeen = 253; TrainLossPerSample =  1.99356750; EvalErr[0]PerSample = 0.55335968; TotalTime = 0.2130s; SamplesPerSecond = 1187.5
MPI Rank 1: 04/28/2016 15:42:47:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: SamplesSeen = 286; TrainLossPerSample =  1.91538321; EvalErr[0]PerSample = 0.53846154; TotalTime = 0.2168s; SamplesPerSecond = 1318.9
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: SamplesSeen = 290; TrainLossPerSample =  2.00558191; EvalErr[0]PerSample = 0.54827586; TotalTime = 0.1561s; SamplesPerSecond = 1857.8
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: SamplesSeen = 297; TrainLossPerSample =  1.89801663; EvalErr[0]PerSample = 0.52188552; TotalTime = 0.1185s; SamplesPerSecond = 2507.3
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: SamplesSeen = 288; TrainLossPerSample =  2.07827977; EvalErr[0]PerSample = 0.59375000; TotalTime = 0.1165s; SamplesPerSecond = 2471.1
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.36 seconds since last report (0.00 seconds on comm.); 4292 samples processed by 2 workers (2139 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 3.15k samplesPerSecond , throughputPerWorker = 1.58k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: SamplesSeen = 281; TrainLossPerSample =  1.93068764; EvalErr[0]PerSample = 0.54448399; TotalTime = 0.2075s; SamplesPerSecond = 1354.0
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: SamplesSeen = 292; TrainLossPerSample =  1.85531301; EvalErr[0]PerSample = 0.51712329; TotalTime = 0.2208s; SamplesPerSecond = 1322.4
MPI Rank 1: 04/28/2016 15:42:48:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: SamplesSeen = 292; TrainLossPerSample =  1.98801565; EvalErr[0]PerSample = 0.57534247; TotalTime = 0.2208s; SamplesPerSecond = 1322.4
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: SamplesSeen = 268; TrainLossPerSample =  2.05808563; EvalErr[0]PerSample = 0.56343284; TotalTime = 0.2156s; SamplesPerSecond = 1242.8
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: SamplesSeen = 270; TrainLossPerSample =  1.81503339; EvalErr[0]PerSample = 0.52222222; TotalTime = 0.1829s; SamplesPerSecond = 1476.1
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: SamplesSeen = 287; TrainLossPerSample =  2.10398514; EvalErr[0]PerSample = 0.58536585; TotalTime = 0.1149s; SamplesPerSecond = 2496.8
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: SamplesSeen = 272; TrainLossPerSample =  1.93305713; EvalErr[0]PerSample = 0.54411765; TotalTime = 0.1171s; SamplesPerSecond = 2323.0
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.36 seconds since last report (0.00 seconds on comm.); 4263 samples processed by 2 workers (2137 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 3.14k samplesPerSecond , throughputPerWorker = 1.57k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: SamplesSeen = 267; TrainLossPerSample =  2.02514086; EvalErr[0]PerSample = 0.52434457; TotalTime = 0.1308s; SamplesPerSecond = 2040.8
MPI Rank 1: 04/28/2016 15:42:49:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: SamplesSeen = 280; TrainLossPerSample =  1.95146823; EvalErr[0]PerSample = 0.51785714; TotalTime = 0.2052s; SamplesPerSecond = 1364.7
MPI Rank 1: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: SamplesSeen = 278; TrainLossPerSample =  1.75049844; EvalErr[0]PerSample = 0.46043165; TotalTime = 0.2161s; SamplesPerSecond = 1286.6
MPI Rank 1: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: SamplesSeen = 288; TrainLossPerSample =  2.01606953; EvalErr[0]PerSample = 0.53472222; TotalTime = 0.2183s; SamplesPerSecond = 1319.6
MPI Rank 1: 04/28/2016 15:42:50:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: SamplesSeen = 174; TrainLossPerSample =  1.98549324; EvalErr[0]PerSample = 0.61494253; TotalTime = 0.1081s; SamplesPerSecond = 1610.1
MPI Rank 1: 		(model aggregation stats) 4-th sync:     2.54 seconds since last report (1.61 seconds on comm.); 7682 samples processed by 2 workers (1020 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 3.02k samplesPerSecond , throughputPerWorker = 1.51k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:52: Finished Epoch[ 2 of 5]: [Training Set] TrainLossPerSample = 1.973157; TotalSamplesSeen = 40960; EvalErrPerSample = 0.54174805; AvgLearningRatePerSample = 0.001953125; EpochTime=6.61665
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:52: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:52: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/28/2016 15:42:53:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1137; TrainLossPerSample =  1.80094771; EvalErr[0]PerSample = 0.51011434; TotalTime = 0.6993s; SamplesPerSecond = 1626.0
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.21 seconds since last report (0.00 seconds on comm.); 4848 samples processed by 2 workers (2247 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 3.99k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:53:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1110; TrainLossPerSample =  1.87991410; EvalErr[0]PerSample = 0.51531532; TotalTime = 0.4558s; SamplesPerSecond = 2435.2
MPI Rank 1: 04/28/2016 15:42:54:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1105; TrainLossPerSample =  1.99663637; EvalErr[0]PerSample = 0.55384615; TotalTime = 0.6725s; SamplesPerSecond = 1643.2
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.15 seconds since last report (0.00 seconds on comm.); 4857 samples processed by 2 workers (2254 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.10k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:54:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1149; TrainLossPerSample =  1.96500956; EvalErr[0]PerSample = 0.52393386; TotalTime = 0.4805s; SamplesPerSecond = 2391.3
MPI Rank 1: 04/28/2016 15:42:55:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1158; TrainLossPerSample =  1.89824895; EvalErr[0]PerSample = 0.53713299; TotalTime = 0.6742s; SamplesPerSecond = 1717.6
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.16 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2322 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:56:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1164; TrainLossPerSample =  1.89120997; EvalErr[0]PerSample = 0.52835052; TotalTime = 0.4898s; SamplesPerSecond = 2376.7
MPI Rank 1: 04/28/2016 15:42:56:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 765; TrainLossPerSample =  1.88116091; EvalErr[0]PerSample = 0.51633987; TotalTime = 0.4031s; SamplesPerSecond = 1897.7
MPI Rank 1: 		(model aggregation stats) 4-th sync:     1.42 seconds since last report (0.64 seconds on comm.); 5870 samples processed by 2 workers (765 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 4.13k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:57: Finished Epoch[ 3 of 5]: [Training Set] TrainLossPerSample = 1.8928518; TotalSamplesSeen = 61440; EvalErrPerSample = 0.52680664; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=4.95521
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:57: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:42:57: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/28/2016 15:42:58:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1137; TrainLossPerSample =  1.86227504; EvalErr[0]PerSample = 0.51451187; TotalTime = 0.4337s; SamplesPerSecond = 2621.4
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4851 samples processed by 2 workers (2290 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 4.15k samplesPerSecond , throughputPerWorker = 2.07k samplesPerSecond
MPI Rank 1: 04/28/2016 15:42:58:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1153; TrainLossPerSample =  1.81808742; EvalErr[0]PerSample = 0.50563747; TotalTime = 0.6970s; SamplesPerSecond = 1654.3
MPI Rank 1: 04/28/2016 15:42:59:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1172; TrainLossPerSample =  1.83978372; EvalErr[0]PerSample = 0.53242321; TotalTime = 0.7086s; SamplesPerSecond = 1653.9
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.18 seconds since last report (0.00 seconds on comm.); 4948 samples processed by 2 workers (2401 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 4.18k samplesPerSecond , throughputPerWorker = 2.09k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:00:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1229; TrainLossPerSample =  1.83801944; EvalErr[0]PerSample = 0.52481692; TotalTime = 0.4751s; SamplesPerSecond = 2587.0
MPI Rank 1: 04/28/2016 15:43:00:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1196; TrainLossPerSample =  1.79660135; EvalErr[0]PerSample = 0.50167224; TotalTime = 0.6769s; SamplesPerSecond = 1767.0
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.17 seconds since last report (0.00 seconds on comm.); 4911 samples processed by 2 workers (2422 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.21k samplesPerSecond , throughputPerWorker = 2.11k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:01:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1226; TrainLossPerSample =  1.87024144; EvalErr[0]PerSample = 0.50407830; TotalTime = 0.4874s; SamplesPerSecond = 2515.2
MPI Rank 1: 04/28/2016 15:43:01:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 722; TrainLossPerSample =  1.78967641; EvalErr[0]PerSample = 0.50692521; TotalTime = 0.3914s; SamplesPerSecond = 1844.8
MPI Rank 1: 		(model aggregation stats) 4-th sync:     1.44 seconds since last report (0.68 seconds on comm.); 5770 samples processed by 2 workers (722 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 4.00k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:02: Finished Epoch[ 4 of 5]: [Training Set] TrainLossPerSample = 1.8321188; TotalSamplesSeen = 81920; EvalErrPerSample = 0.50991211; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=4.9643
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:43:03: Starting Epoch 5: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000 ,block momentum time constant = 2954.6394 ,block learning rate = 1.0000 ,sync period = 2048 samples ,, using Nesterov style block momentum, resetting SGD momentum after sync
MPI Rank 1: minibatchiterator: epoch 4: frames [81920..102400] (first utterance at frame 81920), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:43:03: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/28/2016 15:43:03:  Epoch[ 5 of 5]-Minibatch[   1-   3, 15.00%]: SamplesSeen = 1200; TrainLossPerSample =  1.71422313; EvalErr[0]PerSample = 0.49333333; TotalTime = 0.7427s; SamplesPerSecond = 1615.6
MPI Rank 1: 		(model aggregation stats) 1-th sync:     1.30 seconds since last report (0.00 seconds on comm.); 4879 samples processed by 2 workers (2404 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 3.76k samplesPerSecond , throughputPerWorker = 1.88k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:04:  Epoch[ 5 of 5]-Minibatch[   4-   6, 30.00%]: SamplesSeen = 1204; TrainLossPerSample =  1.88184801; EvalErr[0]PerSample = 0.52408638; TotalTime = 0.5088s; SamplesPerSecond = 2366.1
MPI Rank 1: 04/28/2016 15:43:05:  Epoch[ 5 of 5]-Minibatch[   7-   9, 45.00%]: SamplesSeen = 1233; TrainLossPerSample =  1.74109301; EvalErr[0]PerSample = 0.48418491; TotalTime = 0.7518s; SamplesPerSecond = 1640.0
MPI Rank 1: 		(model aggregation stats) 2-th sync:     1.14 seconds since last report (0.00 seconds on comm.); 4542 samples processed by 2 workers (2059 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 3.97k samplesPerSecond , throughputPerWorker = 1.99k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:05:  Epoch[ 5 of 5]-Minibatch[  10-  12, 60.00%]: SamplesSeen = 1232; TrainLossPerSample =  1.75396705; EvalErr[0]PerSample = 0.50568182; TotalTime = 0.6451s; SamplesPerSecond = 1909.6
MPI Rank 1: 04/28/2016 15:43:06:  Epoch[ 5 of 5]-Minibatch[  13-  15, 75.00%]: SamplesSeen = 1226; TrainLossPerSample =  1.76000122; EvalErr[0]PerSample = 0.50081566; TotalTime = 0.6670s; SamplesPerSecond = 1838.2
MPI Rank 1: 		(model aggregation stats) 3-th sync:     1.21 seconds since last report (0.00 seconds on comm.); 4905 samples processed by 2 workers (2444 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 4.04k samplesPerSecond , throughputPerWorker = 2.02k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:06:  Epoch[ 5 of 5]-Minibatch[  16-  18, 90.00%]: SamplesSeen = 1214; TrainLossPerSample =  1.80829813; EvalErr[0]PerSample = 0.51482702; TotalTime = 0.5132s; SamplesPerSecond = 2365.3
MPI Rank 1: 04/28/2016 15:43:07:  Epoch[ 5 of 5]-Minibatch[  19-  21, 105.00%]: SamplesSeen = 752; TrainLossPerSample =  1.86241174; EvalErr[0]PerSample = 0.51196809; TotalTime = 0.4222s; SamplesPerSecond = 1781.1
MPI Rank 1: 		(model aggregation stats) 4-th sync:     1.53 seconds since last report (0.68 seconds on comm.); 6154 samples processed by 2 workers (1154 by me);
MPI Rank 1: 		(model aggregation stats) 4-th sync: totalThroughput = 4.01k samplesPerSecond , throughputPerWorker = 2.00k samplesPerSecond
MPI Rank 1: 04/28/2016 15:43:08: Finished Epoch[ 5 of 5]: [Training Set] TrainLossPerSample = 1.7933205; TotalSamplesSeen = 102400; EvalErrPerSample = 0.49741211; AvgLearningRatePerSample = 9.7656251e-005; EpochTime=5.19148
MPI Rank 1: 04/28/2016 15:43:08: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:43:08: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 04/28/2016 15:43:08: __COMPLETED__
MPI Rank 1: ~MPIWrapper